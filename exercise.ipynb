{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27afaf05",
   "metadata": {},
   "source": [
    "# Exercise 9: Tracking-by-detection with an integer linear program (ILP)\n",
    "\n",
    "Objective:\n",
    "- Write a pipeline that takes in cell detections and links them across time to obtain lineage trees\n",
    "\n",
    "Methods/Tools:\n",
    "\n",
    "- **`networkx`**: To represent the tracking inputs and outputs as graphs. Tracking is often framed\n",
    "    as a graph optimization problem. Nodes in the graph represent detections, and edges represent links\n",
    "    across time. The \"tracking\" task is then framed as selecting the correct edges to link your detections.\n",
    "- **`motile`**: To set up and solve an Integer Linear Program (ILP) for tracking.\n",
    "    ILP-based methods frame tracking as a constrained optimization problem. The task is to select a subset of nodes/edges from a \"candidate graph\" of all possible nodes/edges. The subset must minimize user-defined costs (e.g. edge distance), while also satisfying a set of tracking constraints (e.g. each cell is linked to at most one cell in the previous frame). Note: this tracking approach is not inherently using\n",
    "    \"deep learning\" - the costs and constraints are usually hand-crafted to encode biological and data-based priors, although cost features can also be learned from data.\n",
    "- **`napari`**: To visualize tracking inputs and outputs. Qualitative analysis is crucial for tuning the \n",
    "    weights of the objective function and identifying data-specific costs and constraints.\n",
    "- **`traccuracy`**: To evaluate tracking results. Metrics such as accuracy can be misleading for tracking,\n",
    "    because rare events such as divisions are much harder than the common linking tasks, and might\n",
    "    be more biologically relevant for downstream analysis. Therefore, it is important to evaluate on\n",
    "    a wide range of error metrics and determine which are most important for your use case.\n",
    "\n",
    "After running through the full tracking pipeline, from loading to evaluation, we will learn how to **incorporate custom costs** based on dataset-specific prior information. As a bonus exercise, \n",
    "you can learn how to **learn the best cost weights** for a task from\n",
    "from a small amount of ground truth tracking information.\n",
    "\n",
    "You can run this notebook on your laptop, a GPU is not needed.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "Set your python kernel to <code>09-tracking</code>\n",
    "</div>\n",
    "\n",
    "Places where you are expected to write code are marked with\n",
    "```\n",
    "### YOUR CODE HERE ###\n",
    "```\n",
    "\n",
    "This notebook was originally written by Benjamin Gallusser, and was edited for 2024 by Caroline Malin-Mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ad255",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# TODO: remove\n",
    "import motile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8469a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import skimage\n",
    "import numpy as np\n",
    "import napari\n",
    "import networkx as nx\n",
    "import scipy\n",
    "\n",
    "\n",
    "import motile\n",
    "\n",
    "import zarr\n",
    "from motile_toolbox.visualization import to_napari_tracks_layer\n",
    "from motile_toolbox.candidate_graph import graph_to_nx\n",
    "import motile_plugin.widgets as plugin_widgets\n",
    "from motile_plugin.backend.motile_run import MotileRun\n",
    "from napari.layers import Tracks\n",
    "import traccuracy\n",
    "from traccuracy import run_metrics\n",
    "from traccuracy.metrics import CTCMetrics, DivisionMetrics\n",
    "from traccuracy.matchers import IOUMatcher\n",
    "from csv import DictReader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from typing import Iterable, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee8217",
   "metadata": {},
   "source": [
    "## Load the dataset and inspect it in napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869845de",
   "metadata": {},
   "source": [
    "For this exercise we will be working with a fluorescence microscopy time-lapse of breast cancer cells with stained nuclei (SiR-DNA). It is similar to the dataset at https://zenodo.org/record/4034976#.YwZRCJPP1qt. The raw data, pre-computed segmentations, and detection probabilities are saved in a zarr, and the ground truth tracks are saved in a csv. The segmentation was generated with a pre-trained StartDist model, so there may be some segmentation errors which can affect the tracking process. The detection probabilities also come from StarDist, and are downsampled in x and y by 2 compared to the detections and raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa6c023",
   "metadata": {},
   "source": [
    "Here we load the raw image data, segmentation, and probabilities from the zarr, and view them in napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646169b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/breast_cancer_fluo.zarr\"\n",
    "data_root = zarr.open(data_path, 'r')\n",
    "image_data = data_root[\"raw\"][:]\n",
    "segmentation = data_root[\"seg\"][:]\n",
    "probabilities = data_root[\"probs\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cd889b",
   "metadata": {},
   "source": [
    "Let's use [napari](https://napari.org/tutorials/fundamentals/getting_started.html) to visualize the data. Napari is a wonderful viewer for imaging data that you can interact with in python, even directly out of jupyter notebooks. If you've never used napari, you might want to take a few minutes to go through [this tutorial](https://napari.org/stable/tutorials/fundamentals/viewer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a92b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(image_data, name=\"raw\")\n",
    "viewer.add_labels(segmentation, name=\"seg\")\n",
    "viewer.add_image(probabilities, name=\"probs\", scale=(1, 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa981d",
   "metadata": {},
   "source": [
    "## Read in the ground truth graph\n",
    "\n",
    "In addition to the image data and segmentations, we also have a ground truth tracking solution.\n",
    "The ground truth tracks are stored in a CSV with five columns: id, time, x, y, and parent_id.\n",
    "\n",
    "Each row in the CSV represents a detection at location (time, x, y) with the given id.\n",
    "If the parent_id is not -1, it represents the id of the parent detection in the previous time frame.\n",
    "For cell tracking, tracks can usually be stored in this format, because there is no merging.\n",
    "With merging, a more complicated data struture would be needed.\n",
    "\n",
    "Note that there are no ground truth segmentations - each detection is just a point representing the center of a cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e5645b",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\"><h3>Task 1: Read in the ground truth graph</h3>\n",
    "\n",
    "For this task, you will read in the csv and store the tracks as a <a href=https://en.wikipedia.org/wiki/Directed_graph>directed graph</a> using the `networkx` library. Take a look at the documentation for the networkx DiGraph <a href=https://networkx.org/documentation/stable/reference/classes/digraph.html>here</a> to learn how to create a graph, add nodes and edges with attributes, and access those nodes and edges.\n",
    "\n",
    "Here are the requirements for the graph:\n",
    "<ol>\n",
    "    <li>Each row in the CSV becomes a node in the graph</li>\n",
    "    <li>The node id is an integer specified by the \"id\" column in the csv</li>\n",
    "    <li>Each node has an integer \"t\" attribute specified by the \"time\" column in the csv</li>\n",
    "    <li>Each node has float \"x\", \"y\" attributes storing the corresponding values from the csv</li>\n",
    "    <li>If the parent_id is not -1, then there is an edge in the graph from \"parent_id\" to \"id\"</li>\n",
    "</ol>\n",
    "\n",
    "You can read the CSV using basic python file io, csv.DictReader, pandas, or any other tool you are comfortable with. If not using pandas, remember to cast your read in values from strings to integers or floats.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354470e",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "def read_gt_tracks():\n",
    "    gt_tracks = nx.DiGraph()\n",
    "    ### YOUR CODE HERE ###\n",
    "    return gt_tracks\n",
    "\n",
    "gt_tracks = read_gt_tracks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to test your implementation\n",
    "assert gt_tracks.number_of_nodes() == 5490, f\"Found {gt_tracks.number_of_nodes()} nodes, expected 5490\"\n",
    "assert gt_tracks.number_of_edges() == 5120, f\"Found {gt_tracks.number_of_edges()} edges, expected 5120\"\n",
    "for node, data in gt_tracks.nodes(data=True):\n",
    "    assert type(node) == int, f\"Node id {node} has type {type(node)}, expected 'int'\"\n",
    "    assert \"t\" in data, f\"'t' attribute missing for node {node}\"\n",
    "    assert type(data[\"t\"]) == int, f\"'t' attribute has type {type(data['t'])}, expected 'int'\"\n",
    "    assert \"x\" in data, f\"'x' attribute missing for node {node}\"\n",
    "    assert type(data[\"x\"]) == float, f\"'x' attribute has type {type(data['x'])}, expected 'float'\"\n",
    "    assert \"y\" in data, f\"'y' attribute missing for node {node}\"\n",
    "    assert type(data[\"y\"]) == float, f\"'y' attribute has type {type(daåa['y'])}, expected 'float'\"\n",
    "print(\"Your graph passed all the tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9fed23",
   "metadata": {},
   "source": [
    "We can also use the helper function `to_napari_tracks_layer` to visualize the ground truth tracks in our napari viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3251d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "widget = plugin_widgets.TreeWidget(viewer)\n",
    "viewer.window.add_dock_widget(widget, name=\"Lineage View\", area=\"bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a17b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_run = MotileRun(\n",
    "    run_name=\"ground_truth\",\n",
    "    tracks=gt_tracks,\n",
    ")\n",
    "\n",
    "widget.view_controller.update_napari_layers(ground_truth_run, time_attr=\"t\", pos_attr=(\"x\", \"y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1064a48",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Build a candidate graph from the detections\n",
    "\n",
    "To set up our tracking problem, we will create a \"candidate graph\" - a DiGraph that contains all possible detections (graph nodes) and links (graph edges) between them.\n",
    "\n",
    "Then we use an optimization method called an integer linear program (ILP) to select the best nodes and edges from the candidate graph to generate our final tracks.\n",
    "\n",
    "To create our candidate graph, we will use the provided StarDist segmentations.\n",
    "Each node in the candidate graph represents one segmentation, and each edge represents a potential link between segmentations. This candidate graph will also contain features that will be used in the optimization task, such as position on nodes and, later, customized scores on edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c2aa7c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h3>Task 2: Extract candidate nodes from the predicted segmentations</h3>\n",
    "First we need to turn each segmentation into a node in a `networkx.DiGraph`. \n",
    "Use <a href=https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops>skimage.measure.regionprops</a> to extract properties from each segmentation, and create a candidate graph with nodes only.\n",
    "\n",
    "\n",
    "Here are the requirements for the output graph:\n",
    "<ol>\n",
    "    <li>Each detection (unique label id) in the segmentation becomes a node in the graph</li>\n",
    "    <li>The node id is the label of the detection</li>\n",
    "    <li>Each node has an integer \"t\" attribute, based on the index into the first dimension of the input segmentation array</li>\n",
    "    <li>Each node has float \"x\" and \"y\" attributes containing the \"x\" and \"y\" values from the centroid of the detection region</li>\n",
    "    <li>The graph has no edges (yet!)</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771392a",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "def nodes_from_segmentation(segmentation: np.ndarray) -> nx.DiGraph:\n",
    "    \"\"\"Extract candidate nodes from a segmentation. \n",
    "\n",
    "    Args:\n",
    "        segmentation (np.ndarray): A numpy array with integer labels and dimensions\n",
    "            (t, y, x).\n",
    "\n",
    "    Returns:\n",
    "        nx.DiGraph: A candidate graph with only nodes.\n",
    "    \"\"\"\n",
    "    cand_graph = nx.DiGraph()\n",
    "    print(\"Extracting nodes from segmentation\")\n",
    "    for t in tqdm(range(len(segmentation))):\n",
    "        seg_frame = segmentation[t]\n",
    "        props = skimage.measure.regionprops(seg_frame)\n",
    "        for regionprop in props:\n",
    "            ### YOUR CODE HERE ###\n",
    "        \n",
    "    return cand_graph\n",
    "\n",
    "cand_graph = nodes_from_segmentation(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9deb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to test your implementation of the candidate graph\n",
    "assert cand_graph.number_of_nodes() == 6123, f\"Found {cand_graph.number_of_nodes()} nodes, expected 6123\"\n",
    "assert cand_graph.number_of_edges() == 0, f\"Found {cand_graph.number_of_edges()} edges, expected 0\"\n",
    "for node, data in cand_graph.nodes(data=True):\n",
    "    assert type(node) == int, f\"Node id {node} has type {type(node)}, expected 'int'\"\n",
    "    assert \"t\" in data, f\"'t' attribute missing for node {node}\"\n",
    "    assert type(data[\"t\"]) == int, f\"'t' attribute has type {type(data['t'])}, expected 'int'\"\n",
    "    assert \"x\" in data, f\"'x' attribute missing for node {node}\"\n",
    "    assert type(data[\"x\"]) == float, f\"'x' attribute has type {type(data['x'])}, expected 'float'\"\n",
    "    assert \"y\" in data, f\"'y' attribute missing for node {node}\"\n",
    "    assert type(data[\"y\"]) == float, f\"'y' attribute has type {type(daåa['y'])}, expected 'float'\"\n",
    "print(\"Your candidate graph passed all the tests!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e74e1e",
   "metadata": {},
   "source": [
    "We can visualize our candidate points using the napari Points layer. You should see one point in the center of each segmentation when we display it using the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47504dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_array = np.array([[data[\"t\"], data[\"x\"], data[\"y\"]] for node, data in cand_graph.nodes(data=True)])\n",
    "cand_points_layer = napari.layers.Points(data=points_array, name=\"cand_points\")\n",
    "viewer.add_layer(cand_points_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4431a4",
   "metadata": {},
   "source": [
    "### Adding Candidate Edges\n",
    "\n",
    "After extracting the nodes, we need to add candidate edges. The `add_cand_edges` function below adds candidate edges to a nodes-only graph by connecting all nodes in adjacent frames that are closer than a given max_edge_distance.\n",
    "\n",
    "Note: At the bottom of the cell, we add edges to our candidate graph with max_edge_distance=50. This is the maximum number of pixels that a cell centroid will be able to move between frames. If you want longer edges to be possible, you can increase this distance, but solving may take longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10eccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_node_frame_dict(cand_graph: nx.DiGraph) -> dict[int, list[Any]]:\n",
    "    \"\"\"Compute dictionary from time frames to node ids for candidate graph.\n",
    "\n",
    "    Args:\n",
    "        cand_graph (nx.DiGraph): A networkx graph\n",
    "\n",
    "    Returns:\n",
    "        dict[int, list[Any]]: A mapping from time frames to lists of node ids.\n",
    "    \"\"\"\n",
    "    node_frame_dict: dict[int, list[Any]] = {}\n",
    "    for node, data in cand_graph.nodes(data=True):\n",
    "        t = data[\"t\"]\n",
    "        if t not in node_frame_dict:\n",
    "            node_frame_dict[t] = []\n",
    "        node_frame_dict[t].append(node)\n",
    "    return node_frame_dict\n",
    "\n",
    "def create_kdtree(cand_graph: nx.DiGraph, node_ids: Iterable[Any]) -> scipy.spatial.KDTree:\n",
    "    positions = [[cand_graph.nodes[node][\"x\"], cand_graph.nodes[node][\"y\"]] for node in node_ids]\n",
    "    return scipy.spatial.KDTree(positions)\n",
    "\n",
    "def add_cand_edges(\n",
    "    cand_graph: nx.DiGraph,\n",
    "    max_edge_distance: float,\n",
    ") -> None:\n",
    "    \"\"\"Add candidate edges to a candidate graph by connecting all nodes in adjacent\n",
    "    frames that are closer than max_edge_distance. Also adds attributes to the edges.\n",
    "\n",
    "    Args:\n",
    "        cand_graph (nx.DiGraph): Candidate graph with only nodes populated. Will\n",
    "            be modified in-place to add edges.\n",
    "        max_edge_distance (float): Maximum distance that objects can travel between\n",
    "            frames. All nodes within this distance in adjacent frames will by connected\n",
    "            with a candidate edge.\n",
    "        node_frame_dict (dict[int, list[Any]] | None, optional): A mapping from frames\n",
    "            to node ids. If not provided, it will be computed from cand_graph. Defaults\n",
    "            to None.\n",
    "    \"\"\"\n",
    "    print(\"Extracting candidate edges\")\n",
    "    node_frame_dict = _compute_node_frame_dict(cand_graph)\n",
    "\n",
    "    frames = sorted(node_frame_dict.keys())\n",
    "    prev_node_ids = node_frame_dict[frames[0]]\n",
    "    prev_kdtree = create_kdtree(cand_graph, prev_node_ids)\n",
    "    for frame in tqdm(frames):\n",
    "        if frame + 1 not in node_frame_dict:\n",
    "            continue\n",
    "        next_node_ids = node_frame_dict[frame + 1]\n",
    "        next_kdtree = create_kdtree(cand_graph, next_node_ids)\n",
    "\n",
    "        matched_indices = prev_kdtree.query_ball_tree(next_kdtree, max_edge_distance)\n",
    "\n",
    "        for prev_node_id, next_node_indices in zip(prev_node_ids, matched_indices):\n",
    "            for next_node_index in next_node_indices:\n",
    "                next_node_id = next_node_ids[next_node_index]\n",
    "                cand_graph.add_edge(prev_node_id, next_node_id)\n",
    "\n",
    "        prev_node_ids = next_node_ids\n",
    "        prev_kdtree = next_kdtree\n",
    "\n",
    "add_cand_edges(cand_graph, max_edge_distance=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9391e4a1",
   "metadata": {},
   "source": [
    "Visualizing the candidate edges in napari is, unfortunately, not yet possible. However, we can print out the number of candidate nodes and edges, and compare it to the ground truth nodes and edgesedges. We should see that we have a few more candidate nodes than ground truth (due to false positive detections) and many more candidate edges than ground truth - our next step will be to use optimization to pick a subset of the candidate nodes and edges to generate our solution tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588427e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Our candidate graph has {cand_graph.number_of_nodes()} nodes and {cand_graph.number_of_edges()} edges\")\n",
    "print(f\"Our ground truth track graph has {gt_tracks.number_of_nodes()} nodes and {gt_tracks.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4000f51",
   "metadata": {},
   "source": [
    "## Checkpoint 1\n",
    "<div class=\"alert alert-block alert-success\"><h3>Checkpoint 1: We have visualized our data in napari and set up a candidate graph with all possible detections and links that we could select with our optimization task. </h3>\n",
    "\n",
    "We will now together go through the `motile` <a href=https://funkelab.github.io/motile/quickstart.html#sec-quickstart>quickstart</a> example before you actually set up and run your own motile optimization. If you reach this checkpoint early, feel free to start reading through the quickstart and think of questions you want to ask!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b3d5b",
   "metadata": {},
   "source": [
    "## Setting Up the Tracking Optimization Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12f2ff",
   "metadata": {},
   "source": [
    "As hinted earlier, our goal is to prune the candidate graph. More formally we want to find a graph $\\tilde{G}=(\\tilde{V}, \\tilde{E})$ whose vertices $\\tilde{V}$ are a subset of the candidate graph vertices $V$ and whose edges $\\tilde{E}$ are a subset of the candidate graph edges $E$.\n",
    "\n",
    "\n",
    "Finding a good subgraph $\\tilde{G}=(\\tilde{V}, \\tilde{E})$ can be formulated as an [integer linear program (ILP)](https://en.wikipedia.org/wiki/Integer_programming) (also, refer to the tracking lecture slides), where we assign a binary variable $x$ and a cost $c$ to each vertex and edge in $G$, and then computing $min_x c^Tx$.\n",
    "\n",
    "A set of linear constraints ensures that the solution will be a feasible cell tracking graph. For example, if an edge is part of $\\tilde{G}$, both its incident nodes have to be part of $\\tilde{G}$ as well.\n",
    "\n",
    "`motile` ([docs here](https://funkelab.github.io/motile/)), makes it easy to link with an ILP in python by implementing common linking constraints and costs. \n",
    "\n",
    "TODO: delete this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840742c0",
   "metadata": {},
   "source": [
    "## Task 3 - Basic tracking with motile\n",
    "<div class=\"alert alert-block alert-info\"><h3>Task 3: Set up a basic motile tracking pipeline</h3>\n",
    "<p>Use the motile <a href=https://funkelab.github.io/motile/quickstart.html#sec-quickstart>quickstart</a> example to set up a basic motile pipeline for our task. \n",
    "\n",
    "Here are some key similarities and differences between the quickstart and our task:\n",
    "<ul>\n",
    "    <li>We do not have scores on our nodes. This means we do not need to include a `NodeSelection` cost.</li>\n",
    "    <li>We also do not have scores on our edges. However, we can use the edge distance as a cost, so that longer edges are more costly than shorter edges. Instead of using the `EdgeSelection` cost, we can use the <a href=https://funkelab.github.io/motile/api.html#edgedistance>`EdgeDistance`</a> cost with `position_attribute=\"pos\"`. You will want a positive weight, since higher distances should be more costly, unlike in the example when higher scores were good and so we inverted them with a negative weight.</li>\n",
    "    <li>Because distance is always positive, and you want a positive weight, you will want to include a negative constant on the `EdgeDistance` cost. If there are no negative selection costs, the ILP will always select nothing, because the cost of selecting nothing is zero.</li>\n",
    "    <li>We want to allow divisions. So, we should pass in 2 to our `MaxChildren` constraint. The `MaxParents` constraint should have 1, the same as the quickstart, because neither task allows merging.</li>\n",
    "    <li>You should include an Appear cost similar to the one in the quickstart.</li>\n",
    "</ul>\n",
    "\n",
    "Once you have set up the basic motile optimization task in the function below, you will probably need to adjust the weight and constant values on your costs until you get a solution that looks reasonable.\n",
    "\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195df8ce",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "def solve_basic_optimization(cand_graph):\n",
    "    \"\"\"Set up and solve the network flow problem.\n",
    "\n",
    "    Args:\n",
    "        graph (motile.TrackGraph): The candidate graph.\n",
    "\n",
    "    Returns:\n",
    "        nx.DiGraph: The networkx digraph with the selected solution tracks\n",
    "    \"\"\"\n",
    "\n",
    "    cand_trackgraph = motile.TrackGraph(cand_graph, frame_attribute=\"t\")\n",
    "    solver = motile.Solver(cand_trackgraph)\n",
    "    ### YOUR CODE HERE ###\n",
    "    solver.solve()\n",
    "    solution_graph = graph_to_nx(solver.get_selected_subgraph())\n",
    "    return solution_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f93f9",
   "metadata": {},
   "source": [
    "Here is a utility function to gauge some statistics of a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ae1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graph_stats(graph, name):\n",
    "    print(f\"{name}\\t\\t{graph.number_of_nodes()} nodes\\t{graph.number_of_edges()} edges\\t{len(list(nx.weakly_connected_components(graph)))} tracks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4497b",
   "metadata": {},
   "source": [
    "Here we actually run the optimization, and compare the found solution to the ground truth.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><h3>Gurobi license error</h3>\n",
    "Please ignore the warning `Could not create Gurobi backend ...`.\n",
    "\n",
    "\n",
    "Our integer linear program (ILP) tries to use the proprietary solver Gurobi. You probably don't have a license, in which case the ILP will fall back to the open source solver SCIP.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dad6f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to actually run the solving and get a solution\n",
    "solution_graph = solve_basic_optimization(cand_graph)\n",
    "\n",
    "# then print some statistics about the solution compared to the ground truth\n",
    "print_graph_stats(solution_graph, \"solution\")\n",
    "print_graph_stats(gt_tracks, \"gt tracks\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b101edc7",
   "metadata": {},
   "source": [
    "If you haven't selected any nodes or edges in your solution, try adjusting your weight and/or constant values. Make sure you have some negative costs or selecting nothing will always be the best solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c9f61",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><h3>Question 1: Interpret your results based on statistics</h3>\n",
    "<p>\n",
    "What do these printed statistics tell you about your solution? What else would you like to know?\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b794d2",
   "metadata": {},
   "source": [
    "## Visualize the Result\n",
    "Rather than just looking at printed statistics about our solution, let's visualize it in `napari`.\n",
    "\n",
    "This involves two steps:\n",
    "1. First, we can add a tracks layer with the solution graph.\n",
    "2. Second, we can add another segmentation layer, where the segmentations are relabeled so that the same cell will be the same color over time. Cells will still change color at division.\n",
    "\n",
    "Note that bad tracking results at this point does not mean that you implemented anything wrong! We still need to customize our costs and constraints to the task before we can get good results. As long as your pipeline selects something, and you can kind of interepret why it is going wrong, that is all that is needed at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34701279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recolor the segmentation\n",
    "\n",
    "from motile_toolbox.visualization.napari_utils import assign_tracklet_ids\n",
    "def relabel_segmentation(\n",
    "    solution_nx_graph: nx.DiGraph,\n",
    "    segmentation: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Relabel a segmentation based on tracking results so that nodes in same\n",
    "    track share the same id. IDs do change at division.\n",
    "\n",
    "    Args:\n",
    "        solution_nx_graph (nx.DiGraph): Networkx graph with the solution to use\n",
    "            for relabeling. Nodes not in graph will be removed from seg. Original\n",
    "            segmentation ids and hypothesis ids have to be stored in the graph so we\n",
    "            can map them back.\n",
    "        segmentation (np.ndarray): Original (potentially multi-hypothesis)\n",
    "            segmentation with dimensions (t,h,[z],y,x), where h is 1 for single\n",
    "            input segmentation.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Relabeled segmentation array where nodes in same track share same\n",
    "            id with shape (t,1,[z],y,x)\n",
    "    \"\"\"\n",
    "    assign_tracklet_ids(solution_nx_graph)\n",
    "    tracked_masks = np.zeros_like(segmentation)\n",
    "    for node, data in solution_nx_graph.nodes(data=True):\n",
    "        time_frame = solution_nx_graph.nodes[node][\"t\"]\n",
    "        previous_seg_id = node\n",
    "        track_id = solution_nx_graph.nodes[node][\"tracklet_id\"]\n",
    "        previous_seg_mask = (\n",
    "            segmentation[time_frame] == previous_seg_id\n",
    "        )\n",
    "        tracked_masks[time_frame][previous_seg_mask] = track_id\n",
    "    return tracked_masks\n",
    "\n",
    "solution_seg = relabel_segmentation(solution_graph, segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf09ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_run = MotileRun(\n",
    "    run_name=\"basic_solution_test\",\n",
    "    tracks=solution_graph,\n",
    "    output_segmentation=np.expand_dims(solution_seg, axis=1)  # need to add a dummy dimension to fit API\n",
    ")\n",
    "\n",
    "widget.view_controller.update_napari_layers(basic_run, time_attr=\"t\", pos_attr=(\"x\", \"y\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac106e5b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><h3>Question 2: Interpret your results based on visualization</h3>\n",
    "<p>\n",
    "How is your solution based on looking at the visualization? When is it doing well? When is it doing poorly?\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa790b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "We were able to understand via visualizing the predicted tracks on the images that the basic solution is far from perfect for this problem.\n",
    "\n",
    "Additionally, we would also like to quantify this. We will use the package [`traccuracy`](https://traccuracy.readthedocs.io/en/latest/) to calculate some [standard metrics for cell tracking](http://celltrackingchallenge.net/evaluation-methodology/). For example, a high-level indicator for tracking performance is called TRA.\n",
    "\n",
    "If you're interested in more detailed metrics, you can look at the false positive (FP) and false negative (FN) nodes, edges and division events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006cb964",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "from skimage.draw import disk\n",
    "def make_gt_detections(data_shape, gt_tracks, radius):\n",
    "    segmentation = np.zeros(data_shape, dtype=\"uint32\")\n",
    "    frame_shape = data_shape[1:]\n",
    "    # make frame with one cell in center with label 1\n",
    "    for node, data in gt_tracks.nodes(data=True):\n",
    "        pos = (data[\"x\"], data[\"y\"])\n",
    "        time = data[\"t\"]\n",
    "        gt_tracks.nodes[node][\"label\"] = node\n",
    "        rr, cc = disk(center=pos, radius=radius, shape=frame_shape)\n",
    "        segmentation[time][rr, cc] = node\n",
    "    return segmentation\n",
    "\n",
    "gt_dets = make_gt_detections(data_root[\"raw\"].shape, gt_tracks, 10)\n",
    "# viewer.add_image(gt_dets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(gt_graph, labels, pred_graph, pred_segmentation):\n",
    "    \"\"\"Calculate metrics for linked tracks by comparing to ground truth.\n",
    "\n",
    "    Args:\n",
    "        gt_graph (networkx.DiGraph): Ground truth graph.\n",
    "        labels (np.ndarray): Ground truth detections.\n",
    "        pred_graph (networkx.DiGraph): Predicted graph.\n",
    "        pred_segmentation (np.ndarray): Predicted dense segmentation.\n",
    "\n",
    "    Returns:\n",
    "        results (dict): Dictionary of metric results.\n",
    "    \"\"\"\n",
    "\n",
    "    gt_graph = traccuracy.TrackingGraph(\n",
    "        graph=gt_graph,\n",
    "        frame_key=\"t\",\n",
    "        label_key=\"label\",\n",
    "        location_keys=(\"x\", \"y\"),\n",
    "        segmentation=labels,\n",
    "    )\n",
    "\n",
    "    pred_graph = traccuracy.TrackingGraph(\n",
    "        graph=pred_graph,\n",
    "        frame_key=\"t\",\n",
    "        label_key=\"tracklet_id\",\n",
    "        location_keys=(\"x\", \"y\"),\n",
    "        segmentation=pred_segmentation,\n",
    "    )\n",
    "\n",
    "    results = run_metrics(\n",
    "        gt_data=gt_graph,\n",
    "        pred_data=pred_graph,\n",
    "        matcher=IOUMatcher(iou_threshold=0.3, one_to_one=True),\n",
    "        metrics=[CTCMetrics(), DivisionMetrics()],\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd8fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(gt_tracks, gt_dets, solution_graph, solution_seg.astype(np.uint32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a8e7b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><h3>Question 3: Interpret your results based on metrics</h3>\n",
    "<p>\n",
    "What additional information, if any, do the metrics give you compared to the statistics and the visualization?\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f9149",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><h2>Checkpoint 2</h2>\n",
    "We have set up and run a basic ILP to get tracks and visualized and evaluated the output.  \n",
    "\n",
    "We will go over the code and discuss the answers to Questions 1, 2, and 3 together soon. If you have extra time, think about what kinds of improvements you could make to the costs and constraints to fix the issues that you are seeing. You can even try tuning your weights and constants, or adding or removing motile Costs and Constraints, and seeing how that changes the output.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea6152",
   "metadata": {},
   "source": [
    "## Customizing the Tracking Task\n",
    "\n",
    "There 3 main ways to encode prior knowledge about your task into the motile tracking pipeline.\n",
    "1. Add an attribute to the candidate graph and incorporate it with an existing cost\n",
    "2. Change the structure of the candidate graph\n",
    "3. Add a new type of cost or constraint\n",
    "\n",
    "The first way is the most common, and is quite flexible, so we will focus on two examples of this type of customization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0471d1",
   "metadata": {},
   "source": [
    "## Task 4 - Add an appear cost, but not at the boundary\n",
    "The Appear cost penalizes starting a new track, encouraging continuous tracks. However, you do not want to penalize tracks that appear in the first frame. In our case, we probably also do not want to penalize appearing at the \"bottom\" of the dataset. The built in Appear cost ([docs here](https://funkelab.github.io/motile/api.html#motile.costs.Appear_)) has an `ignore_attribute` argument, where if the node has that attribute and it evaluates to True, the Appear cost will not be paid for that node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c133dc",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\"><h3>Task 4a: Add an ignore_appear attribute to the candidate graph </h3>\n",
    "<p> \n",
    "For each node on our candidate graph, you should add an attribute `ignore_appear` that evaluates to True if the appear cost should NOT be paid for that node. For nodes that should pay the appear cost, you can either set the attribute to False, or not add the attribute. Nodes should NOT pay the appear cost if they are in the first time frame, or if they are within a certain distance to the \"bottom\" of the dataset. (You will need to determine the coordinate range that you consider the \"bottom\" of the dataset, perhaps by hovering over the napari image layer and seeing what the coordinate values are).\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c01b01",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "def add_appear_ignore_attr(cand_graph):\n",
    "    for node in cand_graph.nodes():\n",
    "        ### YOUR CODE HERE ###\n",
    "        pass  # delete this\n",
    "\n",
    "add_appear_ignore_attr(cand_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09df8fe1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h3>Task 4b: Use the `ignore_appear` attribute in your solver pipeline </h3>\n",
    "<p>Copy your solver pipeline from above, and then adapt the Appear cost to use our new `ignore_appear` attribute. You may also want to adapt the Appear constant value. Then re-solve to see if performance improves.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82873eaa",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "def solve_appear_optimization(cand_graph):\n",
    "    \"\"\"Set up and solve the network flow problem.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.DiGraph): The candidate graph.\n",
    "\n",
    "    Returns:\n",
    "        nx.DiGraph: The networkx digraph with the selected solution tracks\n",
    "    \"\"\"\n",
    "\n",
    "    cand_trackgraph = motile.TrackGraph(cand_graph, frame_attribute=\"t\")\n",
    "    solver = motile.Solver(cand_trackgraph)\n",
    "\n",
    "    ### YOUR CODE HERE ###\n",
    "\n",
    "    solver.solve()\n",
    "    solution_graph = graph_to_nx(solver.get_selected_subgraph())\n",
    "    return solution_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_graph = solve_appear_optimization(cand_graph)\n",
    "solution_seg = relabel_segmentation(solution_graph, segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b499d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "appear_run = MotileRun(\n",
    "    run_name=\"appear_solution\",\n",
    "    tracks=solution_graph,\n",
    "    output_segmentation=np.expand_dims(solution_seg, axis=1)  # need to add a dummy dimension to fit API\n",
    ")\n",
    "\n",
    "widget.view_controller.update_napari_layers(appear_run, time_attr=\"t\", pos_attr=(\"x\", \"y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469b4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(gt_tracks, gt_dets, solution_graph, solution_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09bd609",
   "metadata": {},
   "source": [
    "## Task 5 - Incorporating Known Direction of Motion\n",
    "\n",
    "So far, we have been using motile's EdgeDistance as an edge selection cost, which penalizes longer edges by computing the Euclidean distance between the endpoints. However, in our dataset we see a trend of upward motion in the cells, and the false detections at the top are not moving. If we penalize movement based on what we expect, rather than Euclidean distance, we can select more correct cells and penalize the non-moving artefacts at the same time.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df286ff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h3>Task 5a: Add a drift distance attribute</h3>\n",
    "<p> For this task, we need to determine the \"expected\" amount of motion, then add an attribute to our candidate edges that represents distance from the expected motion direction.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1e4c4",
   "metadata": {
    "tags": [
     "task"
    ]
   },
   "outputs": [],
   "source": [
    "drift = ... ### YOUR CODE HERE ###\n",
    "\n",
    "def add_drift_dist_attr(cand_graph, drift):\n",
    "    for edge in cand_graph.edges():\n",
    "        ### YOUR CODE HERE ###\n",
    "        # get the location of the endpoints of the edge\n",
    "        # then compute the distance between the expected movement and the actual movement\n",
    "        # and save it in the \"drift_dist\" attribute (below)\n",
    "        cand_graph.edges[edge][\"drift_dist\"] = drift_dist\n",
    "\n",
    "add_drift_dist_attr(cand_graph, drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e4553",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h3>Task 5b: Add a drift distance attribute</h3>\n",
    "<p> Now, we set up yet another solving pipeline. This time, we will replace our EdgeDistance\n",
    "cost with an EdgeSelection cost using our new \"drift_dist\" attribute. The weight should be positive, since a higher distance from the expected drift should cost more, similar to our prior EdgeDistance cost. Also similarly, we need a negative constant to make sure that the overall cost of selecting tracks is negative.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c40e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_drift_optimization(cand_graph):\n",
    "    \"\"\"Set up and solve the network flow problem.\n",
    "\n",
    "    Args:\n",
    "        cand_graph (nx.DiGraph): The candidate graph.\n",
    "\n",
    "    Returns:\n",
    "        nx.DiGraph: The networkx digraph with the selected solution tracks\n",
    "    \"\"\"\n",
    "    cand_trackgraph = motile.TrackGraph(cand_graph, frame_attribute=\"t\")\n",
    "    solver = motile.Solver(cand_trackgraph)\n",
    "\n",
    "    ### YOUR CODE HERE ###\n",
    "\n",
    "    solver.solve()\n",
    "\n",
    "    solution_graph = graph_to_nx(solver.get_selected_subgraph())\n",
    "    return solution_graph\n",
    "\n",
    "solution_graph = solve_drift_optimization(cand_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d50ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_graph = solve_drift_optimization(cand_graph)\n",
    "solution_seg = relabel_segmentation(solution_graph, segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad12973",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_run = MotileRun(\n",
    "    run_name=\"drift_solution\",\n",
    "    tracks=solution_graph,\n",
    "    output_segmentation=np.expand_dims(solution_seg, axis=1)  # need to add a dummy dimension to fit API\n",
    ")\n",
    "\n",
    "widget.view_controller.update_napari_layers(drift_run, time_attr=\"t\", pos_attr=(\"x\", \"y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7510f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(gt_tracks, gt_dets, solution_graph, solution_seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb315d",
   "metadata": {},
   "source": [
    "## Checkpoint 4\n",
    "<div class=\"alert alert-block alert-success\"><h3>Checkpoint 4</h3>\n",
    "That is the end of the main exercise! If you have extra time, feel free to go onto the below bonus exercise to see how to learn the weights of your costs instead of setting them manually.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbdeae9",
   "metadata": {},
   "source": [
    "## Bonus: Learning the Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c812d0a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cand_id(gt_node, gt_track, cand_segmentation):\n",
    "    data = gt_track.nodes[gt_node]\n",
    "    return cand_segmentation[data[\"t\"], int(data[\"x\"])][int(data[\"y\"])]\n",
    "\n",
    "def add_gt_annotations(gt_tracks, cand_graph, segmentation):\n",
    "    for gt_node in gt_tracks.nodes():\n",
    "        cand_id = get_cand_id(gt_node, gt_tracks, segmentation)\n",
    "        if cand_id != 0:\n",
    "            if cand_id in cand_graph:\n",
    "                cand_graph.nodes[cand_id][\"gt\"] = True\n",
    "                gt_succs = gt_tracks.successors(gt_node)\n",
    "                gt_succ_matches = [get_cand_id(gt_succ, gt_tracks, segmentation) for gt_succ in gt_succs]\n",
    "                cand_succs = cand_graph.successors(cand_id)\n",
    "                for succ in cand_succs:\n",
    "                    if succ in gt_succ_matches:\n",
    "                        cand_graph.edges[(cand_id, succ)][\"gt\"] = True\n",
    "                    else:\n",
    "                        cand_graph.edges[(cand_id, succ)][\"gt\"] = False\n",
    "    for node in cand_graph.nodes():\n",
    "       if \"gt\" not in cand_graph.nodes[node]:\n",
    "           cand_graph.nodes[node][\"gt\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d6b5b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "validation_times = [0, 3]\n",
    "validation_nodes = [node for node, data in cand_graph.nodes(data=True) \n",
    "                        if (data[\"t\"] >= validation_times[0] and data[\"t\"] < validation_times[1])]\n",
    "print(len(validation_nodes))\n",
    "validation_graph = cand_graph.subgraph(validation_nodes).copy()\n",
    "add_gt_annotations(gt_tracks, validation_graph, segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b71faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_pos_nodes = [node_id for node_id, data in validation_graph.nodes(data=True) if \"gt\" in data and data[\"gt\"] is True]\n",
    "gt_neg_nodes = [node_id for node_id, data in validation_graph.nodes(data=True) if \"gt\" in data and data[\"gt\"] is False]\n",
    "gt_pos_edges = [(source, target) for source, target, data in validation_graph.edges(data=True) if \"gt\" in data and data[\"gt\"] is True]\n",
    "gt_neg_edges = [(source, target) for source, target, data in validation_graph.edges(data=True) if \"gt\" in data and data[\"gt\"] is False]\n",
    "\n",
    "print(f\"{len(gt_pos_nodes) + len(gt_neg_nodes)} annotated: {len(gt_pos_nodes)} True, {len(gt_neg_nodes)} False\")\n",
    "print(f\"{len(gt_pos_edges) + len(gt_neg_edges)} annotated: {len(gt_pos_edges)} True, {len(gt_neg_edges)} False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def get_ssvm_solver(cand_graph):\n",
    "\n",
    "    cand_trackgraph = motile.TrackGraph(cand_graph, frame_attribute=\"t\")\n",
    "    solver = motile.Solver(cand_trackgraph)\n",
    "\n",
    "    solver.add_cost(\n",
    "        motile.costs.EdgeSelection(weight=1.0, constant=-30, attribute=\"drift_dist\")\n",
    "    )\n",
    "    solver.add_cost(motile.costs.Appear(constant=20, ignore_attribute=\"ignore_appear\"))\n",
    "    solver.add_cost(motile.costs.Split(constant=20))\n",
    "\n",
    "    solver.add_constraint(motile.constraints.MaxParents(1))\n",
    "    solver.add_constraint(motile.constraints.MaxChildren(2))\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ff81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssvm_solver = get_ssvm_solver(validation_graph)\n",
    "ssvm_solver.fit_weights(gt_attribute=\"gt\", regularizer_weight=100, max_iterations=50)\n",
    "optimal_weights = ssvm_solver.weights\n",
    "optimal_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f02fb1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_ssvm_solution(cand_graph, solver_weights):\n",
    "    solver = get_ssvm_solver(cand_graph)\n",
    "    solver.weights = solver_weights\n",
    "    solver.solve()\n",
    "    solution_graph = graph_to_nx(solver.get_selected_subgraph())\n",
    "    return solution_graph\n",
    "\n",
    "solution_graph = get_ssvm_solution(cand_graph, optimal_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce459603",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_seg = relabel_segmentation(solution_graph, segmentation)\n",
    "get_metrics(gt_tracks, gt_dets, solution_graph, solution_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88221855",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssvm_run = MotileRun(\n",
    "    run_name=\"ssvm_solution\",\n",
    "    tracks=solution_graph,\n",
    "    output_segmentation=np.expand_dims(solution_seg, axis=1)  # need to add a dummy dimension to fit API\n",
    ")\n",
    "\n",
    "widget.view_controller.update_napari_layers(ssvm_run, time_attr=\"t\", pos_attr=(\"x\", \"y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efa31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d79c0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "custom_cell_magics": "kql",
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "py:percent,ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
