{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39217e9-0d31-488c-9be3-8edc3315717a",
   "metadata": {},
   "source": [
    "# Exercise 1/3: Tracking by detection and simple frame-by-frame matching\n",
    "\n",
    "You could also run this notebook on your laptop, a GPU is not needed.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "Set your python kernel to <code>08-tracking</code>\n",
    "</div>\n",
    "\n",
    "Here we will walk through all basic components of a tracking-by-detection algorithm.\n",
    "\n",
    "You will learn\n",
    "- to **store and visualize** tracking results with `napari` (Exercise 1.1).\n",
    "- to use a robust pretrained deep-learning-based **object detection** algorithm called *StarDist* (Exercise 1.2).\n",
    "- to implement a basic **nearest-neighbor linking algorithm** (Exercises 1.3 - 1.6).\n",
    "- to compute optimal frame-by-frame linking by setting up a **bipartite matching problem** and using a python-based solver (Exercise 1.7).\n",
    "- to compute suitable object **features** for the object linking process with `scikit-image` (Exercise 1.8).\n",
    "\n",
    "Places where you are expected to write code are marked with ```YOUR CODE HERE```."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9ad48-eac6-4836-b41c-bb6b239a619c",
   "metadata": {},
   "source": [
    "This notebook was originally written by Benjamin Gallusser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c728f-b294-4d20-83a9-48acbd227b62",
   "metadata": {},
   "source": [
    "![](figures/tracking.gif \"tracking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee04091-df5a-43f2-bed4-a8643b44127b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bdc7a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stardist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstardist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fill_label_holes, random_label_cmap\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstardist\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m render_label\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstardist\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StarDist2D\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stardist'"
     ]
    }
   ],
   "source": [
    "# Force keras to run on CPU\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Notebook at full width in the browser\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams[\"image.interpolation\"] = \"none\"\n",
    "matplotlib.rcParams['figure.figsize'] = (14, 10)\n",
    "import numpy as np\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm.auto import tqdm\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap\n",
    "from stardist.plot import render_label\n",
    "from stardist.models import StarDist2D\n",
    "from stardist import _draw_polygons\n",
    "from csbdeep.utils import normalize\n",
    "\n",
    "import napari\n",
    "\n",
    "lbl_cmap = random_label_cmap()\n",
    "# Pretty tqdm progress bars \n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e690d63-437a-4850-9071-774d502f2ae3",
   "metadata": {},
   "source": [
    "Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c88d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img_label(img, lbl, img_title=\"image\", lbl_title=\"label\", **kwargs):\n",
    "    fig, (ai,al) = plt.subplots(1,2, gridspec_kw=dict(width_ratios=(1,1)))\n",
    "    im = ai.imshow(img, cmap='gray', clim=(0,1))\n",
    "    ai.set_title(img_title)\n",
    "    ai.axis(\"off\")\n",
    "    al.imshow(render_label(lbl, img=.3*img, normalize_img=False, cmap=lbl_cmap))\n",
    "    al.set_title(lbl_title)\n",
    "    al.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "def preprocess(X, Y, axis_norm=(0,1)):\n",
    "    # normalize channels independently\n",
    "    X = np.stack([normalize(x, 1, 99.8, axis=axis_norm) for x in tqdm(X, leave=True, desc=\"Normalize images\")])\n",
    "    # fill holes in labels\n",
    "    Y = np.stack([fill_label_holes(y) for y in tqdm(Y, leave=True, desc=\"Fill holes in labels\")])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a3c35e-328e-4557-b28c-770206268690",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Inspect the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d42b15-b6a5-4663-b25a-0a272b205d43",
   "metadata": {},
   "source": [
    "For this exercise we will be working with a fluorenscence microscopy time-lapse of breast cancer cells with stained nuclei (SiR-DNA). It is similar to the dataset at https://zenodo.org/record/4034976#.YwZRCJPP1qt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71944856-44f7-454e-ad24-18e8cd0f6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"data/exercise1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72806388-6422-4e6c-8702-a7f5ad45a460",
   "metadata": {},
   "source": [
    "Load the dataset (images and tracking annotations) from disk into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b598b0-c764-4431-b2da-7cfa8e98a3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.stack([imread(xi) for xi in sorted((base_path / \"images\").glob(\"*.tif\"))])  # images\n",
    "y = np.stack([imread(yi) for yi in sorted((base_path / \"gt_tracking\").glob(\"*.tif\"))])  # ground truth annotations\n",
    "assert x.shape == y.shape\n",
    "print(f\"Number of images: {len(x)}\")\n",
    "print(f\"Shape of images: {x[0].shape}\")\n",
    "x, y = preprocess(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984eb94-6c2b-4ff9-be3d-73c552a359fc",
   "metadata": {},
   "source": [
    "Let's visualize some images (by changing `idx`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb824ca9-ec18-4ae4-b230-785a6872aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "plot_img_label(x[idx], y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92453442-bdb7-4f68-a275-41f4130cdf5b",
   "metadata": {},
   "source": [
    "This is ok to take a glimpse, but a dynamic viewer would be much better to understand how cells move. Let's use [napari](https://napari.org/tutorials/fundamentals/getting_started.html) for this. Napari is a wonderful viewer for imaging data that you can interact with in python, even directly out of jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d940810-1349-4ff8-b24f-aea613026afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x, name=\"image\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066a3fd0-71de-4be3-a1d5-deb74ed6e1d7",
   "metadata": {},
   "source": [
    "If you've never used napari, you might want to take a few minutes to go through [this tutorial](https://napari.org/stable/tutorials/fundamentals/viewer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95a443b-6ab2-44de-8b5c-57f16e45a917",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><h3>Napari in a jupyter notebook:</h3>\n",
    "    \n",
    "- To have napari working in a jupyter notebook, you need to use up-to-date versions of napari, pyqt and pyqt5, as is the case in the conda environments provided together with this exercise.\n",
    "- When you are coding and debugging, close the napari viewer with `viewer.close()` to avoid problems with the two event loops of napari and jupyter.\n",
    "- **If a cell is not executed (empty square brackets on the left of a cell) despite you running it, running it a second time right after will usually work.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b214a064-7d49-47ec-a819-9f2e597d1ae5",
   "metadata": {},
   "source": [
    "Let's add the ground truth annotations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78fab6-093f-4943-b8f9-24979463141f",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(y, name=\"labels\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400bd47-dcbd-4dd3-a1b7-722473e291e7",
   "metadata": {},
   "source": [
    "Now it is easy to see that the nuclei have consistent IDs (visualized as random colors) over time.\n",
    "\n",
    "If you zoom in, you will note that the annotations are not perfect segmentations, but rather circles placed roughly in the center of each nucleus.\n",
    "\n",
    "If you look carefully, you will see that there are some cell divisions in this dataset, and the annotation color of the daughter cells does not match the color of the parent cell. This information is stored in an additional table, which we will load now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1555c6-85f3-4630-92ca-5083de9ada54",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = np.loadtxt(base_path / \"gt_tracking\" / \"man_track.txt\", dtype=int)\n",
    "links = pd.DataFrame(data=links, columns=[\"track_id\", \"from\", \"to\", \"parent_id\"])\n",
    "print(\"Links\")\n",
    "links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a7eec-0cf6-44e1-bc63-f2fece70489f",
   "metadata": {},
   "source": [
    "Each row in this table describes a daughter cell track:\n",
    "- it has a unique identifier *track_id*\n",
    "- it starts in frame *from*\n",
    "- it ends in frame *to*\n",
    "- it has a parent cell ID *parent_id*\n",
    "\n",
    "This is the standard data format of the [Cell Tracking Challenge](http://celltrackingchallenge.net) ([Ulman et al. (2017)](https://www.nature.com/articles/nmeth.4473]))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a4d92-87fc-4e0c-a8d7-60fd0bf49683",
   "metadata": {},
   "source": [
    "Here is a function to visualize the tracks of cells over time, including cell divisions. Note that the color of the track is also random and does not match the color of the corresponding spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b305f8e8-a10b-4846-bd66-5c613f8c7b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracks(viewer, y, links=None, name=\"\"):\n",
    "    \"\"\"Utility function to visualize segmentation and tracks\"\"\"\n",
    "    max_label = max(links.max(), y.max()) if links is not None else y.max()\n",
    "    colorperm = np.random.default_rng(42).permutation((np.arange(1, max_label + 2)))\n",
    "    tracks = []\n",
    "    for t, frame in enumerate(y):\n",
    "        centers = skimage.measure.regionprops(frame)\n",
    "        for c in centers:\n",
    "            tracks.append([colorperm[c.label], t, int(c.centroid[0]), int(c.centroid[1])])\n",
    "    tracks = np.array(tracks)\n",
    "    tracks = tracks[tracks[:, 0].argsort()]\n",
    "    \n",
    "    graph = {}\n",
    "    if links is not None:\n",
    "        divisions = links[links[:,3] != 0]\n",
    "        for d in divisions:\n",
    "            if colorperm[d[0]] not in tracks[:, 0] or colorperm[d[3]] not in tracks[:, 0]:\n",
    "                continue\n",
    "            graph[colorperm[d[0]]] = [colorperm[d[3]]]\n",
    "\n",
    "    viewer.add_labels(y, name=f\"{name}_detections\")\n",
    "    viewer.layers[f\"{name}_detections\"].contour = 3\n",
    "    viewer.add_tracks(tracks, name=f\"{name}_tracks\", graph=graph)\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36755434-ed79-41c3-8d18-4658d0ac88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, y, links.to_numpy(), \"ground_truth\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6df6e2-332f-497c-a007-f1e126ffe325",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 1.1\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.1: Highlight the cell divisions</h3>\n",
    "\n",
    "The visualization of the ground truth tracks are useful to grasp this video, but it is still hard see the cell divisions. Given the dense annotations `y` and the track links `links`, write a function to create a new layer that highlights the pairs of daughter cells just after mitosis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30861a2c-621e-4d03-a02f-c7a1b960e415",
   "metadata": {},
   "source": [
    "Expected outcome:<br>\n",
    "<figure style=\"display:inline-block\">\n",
    "    <img src=\"figures/prediv.png\" width=\"400\" />\n",
    "    <figcaption>frame t</figcaption>\n",
    "</figure>\n",
    "<figure style=\"display:inline-block\">\n",
    "    <img src=\"figures/postdiv.png\" width=\"400\" />\n",
    "    <figcaption>frame t+1</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a6b3ad-311f-429e-aab2-4530fb3b85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_divisions(y, links):\n",
    "    \"\"\"Utility function to extract divisions\"\"\"\n",
    "    divisions = np.zeros_like(y)\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    return divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a39e149-9e7b-4566-a7a5-0eb698f4cf69",
   "metadata": {},
   "source": [
    "Feel free to test your function with this minimal example (with toy \"images\" in 1D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d73156-e9df-4ea2-be80-dbae262bb591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_extract_divisions():\n",
    "    y = np.array([\n",
    "        [0, 10, 0, 0],\n",
    "        [0, 11, 12, 13],\n",
    "        [0, 11, 12, 13],\n",
    "        [0, 11, 0, 13]\n",
    "    ])\n",
    "    links = pd.DataFrame([[11, 1, 2, 10], [12, 1, 3, 10]], columns=[\"track_id\", \"from\", \"to\", \"parent_id\"])\n",
    "    divs = extract_divisions(y, links.to_numpy())\n",
    "    expected_divs = np.array([[0, 0, 0, 0], [0, 11, 12, 0], [0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "    if np.all(divs == expected_divs):\n",
    "        print(\"Success :)\")\n",
    "    else:\n",
    "        print(f\"Output\\n{divs}\\ndoes not match expected output\\n{expected_divs}\")\n",
    "\n",
    "test_extract_divisions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a873584-71cf-45d6-8377-c94f2afce4cc",
   "metadata": {},
   "source": [
    "Visualize the output of your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2709a66-23d0-4ea5-9192-685ade6b906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "divisions = extract_divisions(y, links.to_numpy())\n",
    "viewer.add_labels(divisions, name=\"divisions\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ca5c3-96b9-4229-81b4-37669bc3ba11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Object detection using a pre-trained neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76878b3-1f64-4e2e-b781-f133dce8dc94",
   "metadata": {},
   "source": [
    "StarDist (Schmidt et al. (2018) is a robust deep-learning based detection algorithm for cell nuclei. It represents objects as star-convex polygons, which in turn can be represented by a center point and distances along predefined rays going out from the center point.\n",
    "Please refer to the paper for details.\n",
    "\n",
    "We will load a pretraine StarDist model to detect the nuclei in each frame.\n",
    "\n",
    "[Schmidt, Uwe, et al. \"Cell detection with star-convex polygons.\" MICCAI, 2018.](https://link.springer.com/chapter/10.1007/978-3-030-00934-2_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f156b6-2add-4974-ba6f-a4f813b26d50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx = 0\n",
    "model = StarDist2D.from_pretrained(\"2D_versatile_fluo\")\n",
    "(detections, details), (prob, _) = model.predict_instances(x[idx], scale=(1, 1), return_predict=True)\n",
    "plot_img_label(x[idx], detections, lbl_title=\"detections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bff23f-7029-4594-ae2c-ead38652713d",
   "metadata": {},
   "source": [
    "Here we visualize in detail the polygons we have detected with StarDist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb767441-bab9-426f-83e7-5c6b7d094ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord, points, polygon_prob = details['coord'], details['points'], details['prob']\n",
    "plt.figure(figsize=(24,12))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Predicted Polygons\")\n",
    "_draw_polygons(coord, points, polygon_prob, show_dist=True)\n",
    "plt.imshow(x[idx], cmap='gray'); plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Object center probability\")\n",
    "plt.imshow(prob, cmap='magma'); plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06258ea-2cbe-43c6-84b9-e6e45e08082d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 1.2\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.2: Explore the parameters of cell detection</h3>\n",
    "\n",
    "Explore the following aspects of the detection algorithm:     \n",
    "- The `scale` parameter of the function `predict_instances` downscales (< 1) or upscales (> 1) the images by the given factor before feeding them to the neural network. How do the detections change if you adjust it?\n",
    "- Inspect false positive and false negative detections. Do you observe patterns?\n",
    "- So far we have used a StarDist model off the shelf. Luckily, we also have a StarDist model that was trained on a very similar breast cancer cell dataset (from https://zenodo.org/record/4034976#.Yv-aNPFBzao). Load it with `model = StarDist2D(None, name=\"stardist_breast_cancer\", basedir=\"models\")` and qualitatively observe differences.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf20a8-b085-4e1f-b3ee-f0af8798d4c2",
   "metadata": {},
   "source": [
    "Detect centers and segment nuclei in all images of the time lapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc2e533-58b9-4b5b-9c61-adb9cdd8a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = (1.0, 1.0)\n",
    "pred = [model.predict_instances(xi, show_tile_progress=False, scale=scale)\n",
    "              for xi in tqdm(x)]\n",
    "detections = [xi[0] for xi in pred]\n",
    "detections = np.stack([skimage.segmentation.relabel_sequential(d)[0] for d in detections])  # ensure that label ids are contiguous and start at 1 for each frame \n",
    "centers = [xi[1][\"points\"] for xi in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf114a1f-2d24-4976-8cdd-953d93c31469",
   "metadata": {},
   "source": [
    "Visualize the dense detections. Note that they are still not linked and therefore randomly colored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f997dd09-3121-402b-b7b9-9e5498bad2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "viewer.add_labels(detections, name=f\"detections_scale_{scale}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aed356a-d8e7-4b0d-a89c-cc8b61269f0c",
   "metadata": {},
   "source": [
    "We see that the number of detections increases over time, corresponding to the cells that insert the field of view from below during the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23798d-57d7-4a18-a00c-9b7d5982e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(range(len(centers)), [len(xi) for xi in centers])\n",
    "plt.title(f\"Number of detections in each frame (scale={scale})\")\n",
    "plt.xticks(range(len(centers)))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c033125-d4f5-48bb-9b2c-47aa7c8e5ca7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Checkpoint 1\n",
    "<div class=\"alert alert-block alert-success\"><h3>Checkpoint 1: We have good detections, now on to the linking.</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9f5a9a-dfe4-4568-a85d-a1dfc3eba19a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Greedy linking by nearest neighbor\n",
    "\n",
    "The detections in each frame now need to be linked in time to form tracks. In the following exercises, we will explore different ways of doing this.\n",
    "\n",
    "We will start with the simplest algorithm: We take a pair of adjacent frames and compute a distance function between each detection $p \\in P$ in frame $t$ and each detection $q \\in Q$ in frame $t+1$. For example, we can calculate the euclidian distance between the two centroids of detections. This can be written as a matrix of size $|P| \\times |Q|$.\n",
    "\n",
    "We want to minimize the total distance of the links we assign. A *greedy* (locally optimal) algorithm to do so is iteratively linking detections with the minimum distance that remains in the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc3769f-6135-4b42-a779-610353fa7cc1",
   "metadata": {},
   "source": [
    "## Exercise 1.3\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.3: Write a function that computes pairwise euclidian distances given two lists of points.</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ff258-73ba-4fe8-8636-c6f7e65fbfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_euclidian_distance(points0, points1):\n",
    "    dists = np.zeros((len(points0), len(points1)))\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    return dists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8141410c-da23-4fbc-8755-b14b0f79e8e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here are two (almost random ;)) lists of points to test your function on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec05e1f-436d-4309-9cd4-1f47a30ce189",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_points = np.load(\"points.npz\")[\"green\"]\n",
    "cyan_points = np.load(\"points.npz\")[\"cyan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69da1e-cab4-473c-85c1-c45fb1e2ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time dists = pairwise_euclidian_distance(green_points, cyan_points)\n",
    "assert np.allclose(dists, np.load(\"points.npz\")[\"dists_green_cyan\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8a72df-3715-4a24-85a9-1f87a86e85ef",
   "metadata": {},
   "source": [
    "## Exercise 1.4\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.4: Complete a function that greedily extracts a nearest neighbor assignment given a cost matrix.</h3>\n",
    "\n",
    "Test your function with the cell below.\n",
    "    \n",
    "Hints:\n",
    "- Make sure links do not exceed the cost threshold.\n",
    "- Once you've found the minimum in the matrix with the given code below (`row, col`), make sure that the row and column are not picked again in the next step.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6880a24a-7942-4cb8-84fa-ddab9396c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(cost_matrix, threshold=np.finfo(float).max):\n",
    "    \"\"\"Greedy nearest neighbor assignment.\n",
    "    \n",
    "    Each point in both sets can only be assigned once. \n",
    "    \n",
    "    Args:\n",
    "\n",
    "        cost_matrix: m x n matrix with pairwise linking costs of two sets of points.\n",
    "        threshold (int): Maximal cost of links.  \n",
    "\n",
    "    Returns:\n",
    "\n",
    "        Determined matches as tuple of lists (ids_of_rows, ids_of_columns).\n",
    "    \"\"\"\n",
    "\n",
    "    A = cost_matrix.copy().astype(float)\n",
    "    ids_from = []\n",
    "    ids_to = []\n",
    "    \n",
    "    for i in range(min(A.shape[0], A.shape[1])):\n",
    "        row, col = np.unravel_index(A.argmin(), A.shape)\n",
    "        \n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    return np.array(ids_from), np.array(ids_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883a71e2-2e56-4309-8831-09aeb0f0bd5c",
   "metadata": {},
   "source": [
    "Test your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d1056-6502-4f55-9c6c-237308faf14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = np.array([\n",
    "    [8, 2, 8],\n",
    "    [9, 9, 9],\n",
    "    [1, 8, 8],\n",
    "    [8, 3, 8],\n",
    "])\n",
    "idx_from, idx_to = nearest_neighbor(test_matrix, threshold=8)\n",
    "assert np.all(idx_from == [2, 0])\n",
    "assert np.all(idx_to == [0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca8c7dc-e44e-4b5c-b534-b4a4ef3130fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Exercise 1.5\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.5: Complete a thresholded nearest neighbor linker using your functions from exercises 1.3 and 1.4.</h3>\n",
    "\n",
    "You have to complete two methods:\n",
    "    \n",
    "- Method 1 (`linking_cost_function`): Given dense detections in a pair of frames, extract their centroids and calculate pairwise euclidian distances between them. \n",
    "- Method 2 (`_link_two_frames`): We greedily find the nearest neighbors in two frames given the cost matrix. If the cost is below a threshold $\\tau$, link the two objects.\n",
    "    - Complete the function such that it returns all unlinked detections in frame $t$ as death events and all unlinked detections in frame $t+1$ as birth events.\n",
    "    - Explore different values of threshold $\\tau$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5d1a2d-5ab1-4f7d-8408-64b54ebfa7e7",
   "metadata": {},
   "source": [
    "Here you are seeing an abstract base class (`ABC`) for linking detections in a video with some local frame-by-frame algorithm.\n",
    "\n",
    "The class already comes with some useful methods that you won't have to worry about, such as iterating over frames, visualizing linked results as well as sanity checks of inputs.\n",
    "\n",
    "There are two abstract methods (\"gaps\") in `FrameByFrameLinker`:\n",
    "- `linking_cost_function`\n",
    "- `_link_two_frames`\n",
    "\n",
    "In the exercises 1.5 - 1.8, you will make different subclasses of `FrameByFrameLinker`, in which it will be your job to write these two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c279f-5e0f-47f5-b35f-4d275a486161",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameByFrameLinker(ABC):\n",
    "    \"\"\"Abstract base class for linking detections by considering pairs of adjacent frames.\"\"\"\n",
    "    \n",
    "    def link(self, detections, images=None):\n",
    "        \"\"\"Links detections in t frames.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections:\n",
    "            \n",
    "                List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "                \n",
    "            images (optional):\n",
    "            \n",
    "                List of t numpy arrays of shape (x,y).\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "            List of t linking dictionaries, each containing:\n",
    "                \"links\": Tuple of lists (ids frame t, ids frame t+1),\n",
    "                \"births\": List of ids,\n",
    "                \"deaths\": List of ids.\n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        if images is not None:\n",
    "            assert len(images) == len(detections)\n",
    "        else:\n",
    "            images = [None] * len(detections)\n",
    "\n",
    "        links = []\n",
    "        for i in tqdm(range(len(images) - 1), desc=\"Linking\"):\n",
    "            detections0 = detections[i]\n",
    "            detections1 = detections[i+1]\n",
    "            self._assert_relabeled(detections0)\n",
    "            self._assert_relabeled(detections1)\n",
    "            \n",
    "            cost_matrix = self.linking_cost_function(detections0, detections1, images[i], images[i+1])\n",
    "            li = self._link_two_frames(cost_matrix)\n",
    "            self._assert_links(links=li, time=i, detections0=detections0, detections1=detections1) \n",
    "            links.append(li)\n",
    "            \n",
    "        return links\n",
    "\n",
    "    @abstractmethod\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Calculate features for each detection and extract pairwise costs.\n",
    "        \n",
    "        To be overwritten in subclass.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            image0 (optional): image corresponding to detections0\n",
    "            image1 (optional): image corresponding to detections1\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Link two frames.\n",
    "        \n",
    "        To be overwritten in subclass.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "            \"links\":\n",
    "            \n",
    "                Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                - idgs_from: [from0, from1 , ...])\n",
    "                - ids_to: [to0, to1 , ...])\n",
    "\n",
    "            \"births\": List of ids from frame t that are \n",
    "            \"deaths\": List of ids.\n",
    "            \n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def relabel_detections(self, detections, links):\n",
    "        \"\"\"Relabel dense detections according to computed links, births and deaths.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            detections: \n",
    "                 \n",
    "                 List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "                 \n",
    "            links:\n",
    "                \n",
    "                List of t linking dictionaries, each containing:\n",
    "                    \"links\": Tuple of lists (ids frame t, ids frame t+1),\n",
    "                    \"births\": List of ids,\n",
    "                    \"deaths\": List of ids.\n",
    "                Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        detections = detections.copy()\n",
    "        \n",
    "        assert len(detections) - 1 == len(links)\n",
    "        self._assert_relabeled(detections[0])\n",
    "        out = [detections[0]]\n",
    "        n_tracks = out[0].max()\n",
    "        lookup_tables = [{i: i for i in range(1, out[0].max() + 1)}]\n",
    "\n",
    "        for i in tqdm(range(len(links)), desc=\"Recoloring detections\"):\n",
    "            (ids_from, ids_to) = links[i][\"links\"]\n",
    "            births = links[i][\"births\"]\n",
    "            deaths = links[i+1][\"deaths\"] if i+1 < len(links) else []\n",
    "            new_frame = np.zeros_like(detections[i+1])\n",
    "            self._assert_relabeled(detections[i+1])\n",
    "            \n",
    "            lut = {}\n",
    "            for _from, _to in zip(ids_from, ids_to):\n",
    "                # Copy over ID\n",
    "                new_frame[detections[i+1] == _to] = lookup_tables[i][_from]\n",
    "                lut[_to] = lookup_tables[i][_from]\n",
    "\n",
    "            \n",
    "            # Start new track for birth tracks\n",
    "            for b in births:\n",
    "                if b in deaths:\n",
    "                    continue\n",
    "                \n",
    "                n_tracks += 1\n",
    "                lut[b] = n_tracks\n",
    "                new_frame[detections[i+1] == b] = n_tracks\n",
    "                \n",
    "            lookup_tables.append(lut)\n",
    "            out.append(new_frame)\n",
    "                \n",
    "        return np.stack(out)\n",
    "\n",
    "    def _assert_links(self, links, time, detections0, detections1):\n",
    "        if len(links[\"links\"][0]) != len(links[\"links\"][1]):\n",
    "            raise RuntimeError(\"Format of links['links'] not correct.\")\n",
    "            \n",
    "        if sorted([*links[\"links\"][0], *links[\"deaths\"]]) != list(range(1, len(np.unique(detections0)))):\n",
    "            raise RuntimeError(f\"Some detections in frame {time} are not properly assigned as either linked or death.\")\n",
    "            \n",
    "        if sorted([*links[\"links\"][1], *links[\"births\"]]) != list(range(1, len(np.unique(detections1)))):\n",
    "            raise RuntimeError(f\"Some detections in frame {time + 1} are not properly assigned as either linked or birth.\")\n",
    "            \n",
    "        for b in links[\"births\"]:\n",
    "            if b in links[\"links\"][1]:\n",
    "                raise RuntimeError(f\"Links frame {time+1}: Detection {b} marked as birth, but also linked.\")\n",
    "        \n",
    "        for d in links[\"deaths\"]:\n",
    "            if d in links[\"links\"][0]:\n",
    "                raise RuntimeError(f\"Links frame {time}: Detection {d} marked as death, but also linked.\")\n",
    "        \n",
    "        \n",
    "    def _assert_relabeled(self, x):\n",
    "        if x.min() < 0:\n",
    "            raise ValueError(\"Negative ID in detections.\")\n",
    "        if x.min() == 0:\n",
    "            n = x.max() + 1\n",
    "        else:\n",
    "            n = x.max()\n",
    "        if n != len(np.unique(x)):\n",
    "            raise ValueError(\"Detection IDs are not contiguous.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c72b377-bbcc-4a1f-991b-900b6f630a11",
   "metadata": {},
   "source": [
    "Hint: Check out `skimage.measure.regionprops`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89deee7b-881c-467d-ab79-78f29b207fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighborLinkerEuclidian(FrameByFrameLinker):\n",
    "    \"\"\".\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        threshold (float): Maximum euclidian distance for linking.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, threshold=sys.float_info.max, *args, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\" Get centroids from detections and compute pairwise euclidian distances.\n",
    "                \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        \n",
    "        ### YOUR CODE HERE ###\n",
    "        # Extract centroids from detections, then apply your function from Exercise 1.3\n",
    "        \n",
    "        dists = np.zeros((detections0.max(), detections1.max()))\n",
    "        \n",
    "        return dists\n",
    "    \n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Greedy nearest neighbor assignment.\n",
    "\n",
    "        Each point in both sets can only be assigned once. \n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix containing pairwise linking costs of two sets of points.\n",
    "\n",
    "        Returns:\n",
    "            \"links\":\n",
    "\n",
    "                Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists: \n",
    "                - idgs_from: [from0, from1 , ...])\n",
    "                - ids_to: [to0, to1 , ...])\n",
    "\n",
    "            \"births\": List of ids from frame t that are \n",
    "            \"deaths\": List of ids.\n",
    "            \n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Your function from exercise 1.4\n",
    "        ids_from, ids_to = nearest_neighbor(cost_matrix)\n",
    "        \n",
    "        births = np.array([### YOUR CODE HERE ###])\n",
    "        deaths = np.array([### YOUR CODE HERE ###])\n",
    "            \n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from += 1\n",
    "        ids_to += 1\n",
    "        births += 1\n",
    "        deaths += 1\n",
    "        \n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005234b-9c4b-4c60-8656-00d0a92790fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_linker = NearestNeighborLinkerEuclidian(threshold=1000) # Explore different values of `threshold`\n",
    "nn_linker = NearestNeighborLinkerEuclidian(threshold=50) # Solution param\n",
    "nn_links = nn_linker.link(detections)\n",
    "nn_tracks = nn_linker.relabel_detections(detections, nn_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40291085-f94c-4925-857b-00c5162829b7",
   "metadata": {},
   "source": [
    "Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76932eb8-0186-4777-8818-8e976940f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, nn_tracks, name=\"nn\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ab42b7-ef07-4476-bc7d-d329ea91636b",
   "metadata": {},
   "source": [
    "## Checkpoint 2\n",
    "<div class=\"alert alert-block alert-success\"><h3>Checkpoint 2: We built a basic tracking algorithm from scratch :).</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f241c4fa-e205-4de4-b9c6-7c0237459f9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 1.6\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.6: Estimate the global drift of the data</h3>\n",
    "\n",
    "We can observe that all cells move upwards with an approximately constant displacement in each timestep. Below you have a slightly modified version of `NearestNeighborLinkerEuclidian` with a modified `linking_cost_function` that models linear drift.\n",
    "\n",
    "Find values of `threshold` and `drift` that lead to an improved solution compared to exercise 1.5.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7f0eb-19f1-42e8-baae-52ddb0a5c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighborLinkerDriftCorrection(NearestNeighborLinkerEuclidian):\n",
    "    \"\"\".\n",
    "    \n",
    "    Args:\n",
    "        \n",
    "        drift: tuple for drift correction per frame.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, drift, *args, **kwargs):\n",
    "        self.drift = np.array(drift)\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\" Get centroids from detections and compute pairwise euclidian distances with drift correction.\n",
    "                \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        # regionprops regions are sorted by label\n",
    "        regions0 = skimage.measure.regionprops(detections0)\n",
    "        points0 = [np.array(r.centroid) for r in regions0]\n",
    "        \n",
    "        regions1 = skimage.measure.regionprops(detections1)\n",
    "        points1 = [np.array(r.centroid) for r in regions1]\n",
    "        \n",
    "        dists = []\n",
    "        for p0 in points0:\n",
    "            for p1 in points1:\n",
    "                dists.append(np.sqrt(((p0 + self.drift - p1)**2).sum()))\n",
    "\n",
    "        dists = np.array(dists).reshape(len(points0), len(points1))\n",
    "        \n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a706de6-da8f-4503-870b-86fd4aca123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "drift_linker = NearestNeighborLinkerDriftCorrection(threshold=1000, drift=(0, 0))\n",
    "drift_links = drift_linker.link(detections)\n",
    "drift_tracks = drift_linker.relabel_detections(detections, drift_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36e7a0f-fe86-477f-a282-3b296e35c302",
   "metadata": {},
   "source": [
    "Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2c9e3-6dbc-4f4a-b66b-44f7852396ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, drift_tracks, name=\"drift\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c96e9e0-0fcc-4f2b-b635-3797df6e8ff9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimal frame-by-frame matching (*Linear assignment problem* or *Weighted bipartite matching*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd64d6-7428-41dc-b483-47bad2ae4627",
   "metadata": {},
   "source": [
    "The nearest neighbor algorithm above will not pick the best solution in many cases. For example, it does not consider the local arrangement of a few detections to create links, something which the human visual system is very good at.\n",
    "\n",
    "We need a better optimization algorithm to minimize the total minimal linking distance between two frames. To use a classic and efficient optimization algorithm, we will represent this linking problem as a bipartite graph. Here is an example:\n",
    "\n",
    "<img src=\"figures/bipartite_graph.png\" width=\"300\"/>\n",
    "\n",
    "Red vertices correspond to detections in frame $t$, blue vertices to detections in frame $t+1$. Since we know that we don't want to link a detection to another one from the same frame, possible edges only connect blue vertices to red vertices, but not within each set.\n",
    "\n",
    "We can also put weights on the edges, which correspond the distanes we have calculated. The task is now to prune the edges of this graph such that each vertex has at most one incident edge. This is called a *weighted bipartite matching* or *linear assignment problem (LAP)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8882b2-f86a-4f8a-9ece-4789f75752bf",
   "metadata": {},
   "source": [
    "In the seminal tracking algorithm proposed by Jaqaman et al. (2008), the bipartite matching additionally includes cost for not linking a vertex. An unlinked vertex from frame $t$ corresponds to the death of a cell, an unlinked vertex from frame $t+1$ to the birth of a cell. Here is the cost matrix in detail:\n",
    "\n",
    "<img src=\"figures/LAP_cost_matrix.png\" width=\"300\"/>\n",
    "\n",
    "\n",
    "from [Jaqaman, Khuloud, et al. \"Robust single-particle tracking in live-cell time-lapse sequences.\" Nature Methods (2008)](https://www.nature.com/articles/nmeth.1237)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c73cb9b-81c2-4d7b-8a53-3ab2497cb995",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 1.7\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.7: Perform optimal frame-by-frame linking</h3>\n",
    "\n",
    "Set up the cost matrix following Jaqaman et al. (2008) such that you can use [`scipy.optimize.linear_sum_assignment`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html) to solve the matching problem in the bipartite graph.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8db520-59f2-4d81-ab57-9f545fba518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BipartiteMatchingLinker(FrameByFrameLinker):\n",
    "    \"\"\".\n",
    "    \n",
    "    Args:\n",
    "        threshold (float): Maximum euclidian distance for linking.\n",
    "        drift: tuple of (x,y) drift correction per frame.\n",
    "        birth_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "        death_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold=sys.float_info.max,\n",
    "        drift=(0,0),\n",
    "        birth_cost_factor=1.05,\n",
    "        death_cost_factor=1.05,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.threshold = threshold\n",
    "        self.drift = np.array(drift)\n",
    "        self.birth_cost_factor = birth_cost_factor\n",
    "        self.death_cost_factor = death_cost_factor\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\" Get centroids from detections and compute pairwise euclidian distances with drift correction.\n",
    "                \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        dists = np.zeros((detections0.max(), detections1.max()))\n",
    "        return dists\n",
    "    \n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Weighted bipartite matching with square matrix from Jaqaman et al (2008).\n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix.\n",
    "\n",
    "        Returns:\n",
    "        \n",
    "            Linking dictionary:\n",
    "                \"links\": Tuple of lists (ids frame t, ids frame t+1),\n",
    "                \"births\": List of ids,\n",
    "                \"deaths\": List of ids.\n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        \n",
    "        cost_matrix = cost_matrix.copy().astype(float)\n",
    "        b = self.birth_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "        d = self.death_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "        no_link = max(cost_matrix.max(), max(b, d)) * 1e9\n",
    "        \n",
    "        \n",
    "        min_objs = min(cost_matrix.shape[0], cost_matrix.shape[1])\n",
    "        ids_from = np.arange(min_objs)\n",
    "        ids_to = np.arange(min_objs)\n",
    "        births = np.arange(min_objs, cost_matrix.shape[1])\n",
    "        deaths = np.arange(min_objs, cost_matrix.shape[0])\n",
    "        \n",
    "        ### YOUR CODE HERE (REPLACE THE DUMMY INITIALIZATIONS FOR THE RETURN VARIABLES ABOVE) ###\n",
    "                        \n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from += 1\n",
    "        ids_to += 1\n",
    "        births += 1\n",
    "        deaths += 1\n",
    "        \n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697622ea-e7fd-4322-b538-a754106f2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_linker = BipartiteMatchingLinker(threshold=50, drift=(-20, 0), birth_cost_factor=1.05, death_cost_factor=1.05)\n",
    "bm_links = bm_linker.link(detections)\n",
    "bm_tracks = bm_linker.relabel_detections(detections, bm_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92ec76-0bda-4565-9c3b-34ff43c99ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, bm_tracks, name=\"bm\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27e1a02-739c-43de-ae50-c893d9e1a71e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other suitable features for linking cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9385bdf3-8158-4d6e-a4c7-1f29e32df976",
   "metadata": {},
   "source": [
    "## Exercise 1.8\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.8: Explore different features for assigment problem</h3>\n",
    "\n",
    "Explore solving the assignment problem based different features and cost functions.\n",
    "For example:\n",
    "- Different morphological properties of detections (e.g. using `skimage.measure.regionprops`).\n",
    "- Extract texture features from the images, e.g. mean intensity for each detection.\n",
    "- Pairwise *Intersection over Union (IoU)* of detections.\n",
    "- ...\n",
    "\n",
    "Feel free to share features that improved the results with the class :).    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a57ae83-0833-41a8-91dd-fe676f82aa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourLinker(BipartiteMatchingLinker):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\" Your very smart cost function for frame-by-frame linking.\n",
    "                \n",
    "        Args:\n",
    "        \n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            image0 (optional): image corresponding to detections0\n",
    "            image1 (optional): image corresponding to detections1\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "            m x n cost matrix \n",
    "        \"\"\"\n",
    "        return np.zeros((detections0.max(), detections1.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd60b85-4bde-4e1a-bb8a-0a35c1514b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_linker = YourLinker()\n",
    "your_links = your_linker.link(detections)\n",
    "your_tracks = your_linker.relabel_detections(detections, your_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a293a-4026-4bfb-b0c0-cfaeb5b2ca70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
