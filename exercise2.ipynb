{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f53e266-571a-48a3-a881-e9a2e60d25b5",
   "metadata": {},
   "source": [
    "# Exercise 2/3: Tracking with two-step Linear Assignment Problem (LAP)\n",
    "\n",
    "Here we will use an extended version of the bipartite matching algorithm we implemented in exercise 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707e9cdf-d9f7-41e3-902d-acf7806e21e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Introduction to the two-step Linear Assignment Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244a289-61ee-4647-8895-3a8ae8005462",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true",
    "tags": []
   },
   "source": [
    "In the previous exercise, we have been able to track individual cells over time by matching detections one-to-one in adjacent frames. However, there are multiple phenomena that this model does not capture:\n",
    "- If a cell is not detected in some frame, for example due to going out of focus, its resulting track will be split apart. \n",
    "- For tracing cell lineages, we want to capture the connection between mother and daughter cells in mitosis. To do this, we have to link one object in frame $t$ to two objects in frame $t+1$, but the bipartite graph matching formulation (also called *Linear Assignment Problem (LAP)*) we have implemented in exercise 1 only models one-to-one links.\n",
    "\n",
    "To account for these processes, Jaqaman et al. (2008) have introduced a second linear assignment problem that is applied to the output tracks (termed *tracklets*) of the frame-by-frame LAP from exercise 1.\n",
    "\n",
    "Here is the cost matrix or this LAP. For $N_T$ tracklets, it has shape $3N_T \\times 3N_T$.\n",
    "\n",
    "<img src=\"figures/LAP_cost_matrix_2.png\" width=\"500\"/>\n",
    "\n",
    "[Jaqaman et al. (2008). Robust single-particle tracking in live-cell time-lapse sequences. Nature methods, 5(8), 695-702.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2747604/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ae6e8-eb9f-4398-814a-09db5c13d8c5",
   "metadata": {},
   "source": [
    "This LAP is run only once for an entire time-lapse, in contrast to the frame-by-frame LAPs from step 1.\n",
    "\n",
    "The costs for linking tracklets are defined in the following way:\n",
    "- Tracklets can appear (lower left block) and disappear (upper right block), just as in step 1.\n",
    "- Tracklet beginnings can be connected to tracklet ends, called gap closing (upper left block).\n",
    "- Tracklet beginnings (at time $t$) can be connected to intermediate points of tracklets at time $t$ (center left block). This allows for a division.\n",
    "- Conversely, also tracklet endings (at time $t$) can be connected to intermediate points of tracklets at time $t$ (upper middle block). This would correspond to merging cells. As we often know a priori that this is not feasible, this block of the matrix is usually set as invalid.\n",
    "\n",
    "Please refer to Jaqaman et al. (2008) for a detailed description of the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e783ae3e-81c6-4e2a-8c31-5c4c0a8c1b93",
   "metadata": {},
   "source": [
    "Instead of implementing this more involved LAP, we will use an ImageJ/Fiji implementation of it to see how it performs on the dataset from exercise 1. The implementation is part of the plugin *TrackMate* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c78487e-0b30-468f-a404-65489fda36be",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true",
    "tags": []
   },
   "source": [
    "## Exercise 2.1\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.1: Run LAP tracking in ImageJ/Fiji with TrackMate.</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22691f9-1447-4255-899b-da293ef1e308",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Install ImageJ/Fiji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406eb9d-0b34-4e92-be36-579909aaa819",
   "metadata": {},
   "source": [
    "Download Fiji from https://imagej.net/software/fiji/downloads and extract the zip directory:\n",
    "- on Windows and Linux: anywhere, for example in Desktop.\n",
    "- on MacOS: into the `Applications` directory.\n",
    "\n",
    "The TrackMate plugin is already included in Fiji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6f8c8-5ccb-4307-9347-8ae0a646ae88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Install StarDist inference for TrackMate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c98e2-6bda-4c31-b669-392fdec81b49",
   "metadata": {},
   "source": [
    "In exercise 1, we have seen that a deep-learning-based detector (for example StarDist) trained on a similar dataset extracts accurate detections of the nuclei. We will do this again in TrackMate. This requires the installation of some additional plugins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc590c-7643-43e4-aaa3-f9a56f4c5925",
   "metadata": {},
   "source": [
    "Start up Fiji and go to `Help -> Update`, then to `Manage update sites` in the appearing window.\n",
    "\n",
    "Select `TrackMate-StarDist`, `StarDist` and `CSBDeep` and press `Close`. Finally, click `Apply changes` to start the installation. After it is done, restart Fiji.\n",
    "\n",
    "<img src=\"figures/trackmate/install.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b574cc15-0571-4215-ab83-699cd809f652",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f2caa-b3a5-4988-ac87-dc7a0e5ce0f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "We will use the same dataset as in exercise 1. It is part of the tracking exercise GitHub repository at `tracking/data/exercise1`.\n",
    "\n",
    "Drag and drop the `images` directory into Fiji and click `OK` in the appearing prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c28db0-c309-4987-aa8f-3a6b88ee83fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Start TrackMate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06a6bf-016d-407f-a554-1e5b466175d4",
   "metadata": {},
   "source": [
    "You can either use the Fiji search bar or go to `Plugins -> tracking -> TrackMate`.\n",
    "\n",
    "<img src=\"figures/trackmate/start_trackmate.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58e882-7297-4a00-a682-5ebd48d253ff",
   "metadata": {},
   "source": [
    "TrackMate might prompt you to swap axes to internally represent the set of images as a time series, please confirm.\n",
    "\n",
    "<img src=\"figures/trackmate/swap_axes.png\" width=\"300\"/>.\n",
    "\n",
    "Press `next` to skip the dataset cropping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447eff14-d2bc-4373-8ef6-8030acb2e99f",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Extract detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf886d-2404-4957-9447-26e6f41588f8",
   "metadata": {},
   "source": [
    "To use the StarDist model pretrained on a similar dataset, select `StarDist detector custom model`. The model is part of the tracking exercise GitHub repository at `tracking/models/TF_SavedModel.zip` (no need to unzip).\n",
    "\n",
    "<img src=\"figures/trackmate/stardist_pretrained.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f4a2fe-bdf9-4caf-9da4-83be0295a10e",
   "metadata": {},
   "source": [
    "Press `next` to run StarDist. After it is done, you can skip the `Initial thresholding` and `Set filters on spots steps` by pressing `next`.\n",
    "\n",
    "You should get nice detections like these ones:\n",
    "\n",
    "<img src=\"figures/trackmate/detections.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752269c-250b-4a51-873c-8f9ce83125a8",
   "metadata": {
    "incorrectly_encoded_metadata": "tags=[] jp-MarkdownHeadingCollapsed=true",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Linking frame-by-frame LAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acb9a3b-cc18-44f9-b4f4-a50ae6e58985",
   "metadata": {},
   "source": [
    "First, we will run the `Simple LAP tracker`. We set\n",
    "- `Gap-closing max distance: 0` and \n",
    "- `Gap-closing max frame gap: 0`\n",
    "\n",
    "and run the linking.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9033c6-24fe-4788-993a-b28ea4928031",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 2.2\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.2: Inspect the \"Simple LAP tracker\" results and compare to the results from exercise 1.</h3>\n",
    "What are the differences? What are possible reasons?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b561ea0-d1e1-4db6-a48f-b40731c980b9",
   "metadata": {},
   "source": [
    "Here are some reasonable visualization setting for this dataset (press the pliers icon to adapt).\n",
    "\n",
    "Feel free to play around to improve visualization of things you are interested in.\n",
    "\n",
    "<img src=\"figures/trackmate/visualization_settings.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486dd92-d3c2-408f-b84a-b0b8e4a3e94f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Linking with two-step LAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa6f49-bcfb-48ef-b8c9-c6cba054feb2",
   "metadata": {},
   "source": [
    "Go one step back in the TrackMate panel and select `LAP tracker` for linking now. You will be presented with the options described at the top of this notebook.\n",
    "Using all the knowledge you have by now about this dataset, set up the options to extract a satisfying tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217dd10e-2dfa-4761-abb1-f72e30fc8be7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Exercise 2.3\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 2.3: Using all the knowledge you have by now about this dataset to set up the LAP tracker options.</h3>    \n",
    "</div>\n",
    "\n",
    "\n",
    "Note on `feature penalties`: TrackMate uses a range of features to calculate distances between frames. By setting a penalty for a certain feature, you multiply that dimension of the distance vector. For example, if you set the penalty for `Y=100`, you will not get any vertical links."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f91466-9a79-4734-ad5a-beac44eba54b",
   "metadata": {},
   "source": [
    "<img src=\"figures/trackmate/results.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6478945-4e3f-4b71-8e02-96785bdd3d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
