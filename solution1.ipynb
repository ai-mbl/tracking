{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb76ef8f",
   "metadata": {},
   "source": [
    "# Exercise 1: Tracking by detection and simple frame-by-frame matching\n",
    "\n",
    "You could also run this notebook on your laptop, a GPU is not needed.\n",
    "\n",
    "![](figures/tracking.gif \"tracking\")\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "Set your python kernel to <code>08-tracking</code>\n",
    "</div>\n",
    "\n",
    "Here we will walk through all basic components of a tracking-by-detection algorithm.\n",
    "\n",
    "You will learn\n",
    "- to **store and visualize** tracking results with `napari` (Exercise 1.1).\n",
    "- to use a robust pretrained deep-learning-based **object detection** algorithm called *StarDist* (Exercise 1.2).\n",
    "- to implement a basic **nearest-neighbor linking algorithm** (Exercises 1.3 - 1.6).\n",
    "- to compute optimal frame-by-frame linking by setting up a **bipartite matching problem** and using a python-based solver (Exercise 1.7).\n",
    "- to compute suitable object **features** for the object linking process with `scikit-image` (Exercise 1.8).\n",
    "\n",
    "Places where you are expected to write code are marked with\n",
    "```\n",
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################\n",
    "```\n",
    "\n",
    "This notebook was originally written by Benjamin Gallusser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c5018",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4902a5c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "# Force keras to run on CPU\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Notebook at full width in the browser\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams[\"image.interpolation\"] = \"none\"\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (14, 10)\n",
    "import numpy as np\n",
    "from tifffile import imread, imwrite\n",
    "from tqdm import tqdm\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from stardist import fill_label_holes, random_label_cmap\n",
    "from stardist.plot import render_label\n",
    "from stardist.models import StarDist2D\n",
    "from stardist import _draw_polygons\n",
    "from csbdeep.utils import normalize\n",
    "\n",
    "import napari\n",
    "\n",
    "lbl_cmap = random_label_cmap()\n",
    "# Pretty tqdm progress bars\n",
    "! jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cc6c73",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb824a6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot_img_label(img, lbl, img_title=\"image\", lbl_title=\"label\", **kwargs):\n",
    "    fig, (ai, al) = plt.subplots(1, 2, gridspec_kw=dict(width_ratios=(1, 1)))\n",
    "    im = ai.imshow(img, cmap=\"gray\", clim=(0, 1))\n",
    "    ai.set_title(img_title)\n",
    "    ai.axis(\"off\")\n",
    "    al.imshow(render_label(lbl, img=0.3 * img, normalize_img=False, cmap=lbl_cmap))\n",
    "    al.set_title(lbl_title)\n",
    "    al.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def preprocess(X, Y, axis_norm=(0, 1)):\n",
    "    # normalize channels independently\n",
    "    X = np.stack(\n",
    "        [\n",
    "            normalize(x, 1, 99.8, axis=axis_norm)\n",
    "            for x in tqdm(X, leave=True, desc=\"Normalize images\")\n",
    "        ]\n",
    "    )\n",
    "    # fill holes in labels\n",
    "    Y = np.stack(\n",
    "        [fill_label_holes(y) for y in tqdm(Y, leave=True, desc=\"Fill holes in labels\")]\n",
    "    )\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b00b4c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inspect the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384c30e4",
   "metadata": {},
   "source": [
    "For this exercise we will be working with a fluorescence microscopy time-lapse of breast cancer cells with stained nuclei (SiR-DNA). It is similar to the dataset at https://zenodo.org/record/4034976#.YwZRCJPP1qt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"data/exercise1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbff2c4",
   "metadata": {},
   "source": [
    "Load the dataset (images and tracking annotations) from disk into this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44606c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.stack(\n",
    "    [imread(xi) for xi in sorted((base_path / \"images\").glob(\"*.tif\"))]\n",
    ")  # images\n",
    "y = np.stack(\n",
    "    [imread(yi) for yi in sorted((base_path / \"gt_tracking\").glob(\"*.tif\"))]\n",
    ")  # ground truth annotations\n",
    "assert x.shape == y.shape\n",
    "print(f\"Number of images: {len(x)}\")\n",
    "print(f\"Shape of images: {x[0].shape}\")\n",
    "x, y = preprocess(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca715e06",
   "metadata": {},
   "source": [
    "Let's visualize some images (by changing `idx`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f274d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "plot_img_label(x[idx], y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcb76f8",
   "metadata": {},
   "source": [
    "This is ok to take a glimpse, but a dynamic viewer would be much better to understand how cells move. Let's use [napari](https://napari.org/tutorials/fundamentals/getting_started.html) for this. Napari is a wonderful viewer for imaging data that you can interact with in python, even directly out of jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f097708",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x, name=\"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030bbb0",
   "metadata": {},
   "source": [
    "If you've never used napari, you might want to take a few minutes to go through [this tutorial](https://napari.org/stable/tutorials/fundamentals/viewer.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542fb6f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"><h3>Napari in a jupyter notebook:</h3>\n",
    "\n",
    "- To have napari working in a jupyter notebook, you need to use up-to-date versions of napari, pyqt and pyqt5, as is the case in the conda environments provided together with this exercise.\n",
    "- When you are coding and debugging, close the napari viewer with `viewer.close()` to avoid problems with the two event loops of napari and jupyter.\n",
    "- **If a cell is not executed (empty square brackets on the left of a cell) despite you running it, running it a second time right after will usually work.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3622e96",
   "metadata": {},
   "source": [
    "Let's add the ground truth annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57758684",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(y, name=\"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9033bc",
   "metadata": {},
   "source": [
    "Now it is easy to see that the nuclei have consistent IDs (visualized as random colors) over time.\n",
    "\n",
    "If you zoom in, you will note that the annotations are not perfect segmentations, but rather circles placed roughly in the center of each nucleus.\n",
    "\n",
    "If you look carefully, you will see that there are some cell divisions in this dataset, and the annotation color of the daughter cells does not match the color of the parent cell. This information is stored in an additional table, which we will load now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fce68",
   "metadata": {},
   "source": [
    "Let's load in the cell divisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a198e899",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "links = np.loadtxt(base_path / \"gt_tracking\" / \"man_track.txt\", dtype=int)\n",
    "links = pd.DataFrame(data=links, columns=[\"track_id\", \"from\", \"to\", \"parent_id\"])\n",
    "print(\"Links\")\n",
    "links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd0e28",
   "metadata": {},
   "source": [
    "Each row in this table describes a daughter cell track:\n",
    "- it has a unique identifier *track_id*\n",
    "- it starts in frame *from*\n",
    "- it ends in frame *to*\n",
    "- it has a parent cell ID *parent_id*\n",
    "\n",
    "This is the standard data format of the [Cell Tracking Challenge](http://celltrackingchallenge.net) ([Ulman et al. (2017)](https://www.nature.com/articles/nmeth.4473]))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f00b5a3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Here is a function to visualize the tracks of cells over time, including cell divisions. Note that the color of the track is also random and does not match the color of the corresponding spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0910e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracks(viewer, y, links=None, name=\"\"):\n",
    "    \"\"\"Utility function to visualize segmentation and tracks\"\"\"\n",
    "    max_label = max(links.max(), y.max()) if links is not None else y.max()\n",
    "    colorperm = np.random.default_rng(42).permutation((np.arange(1, max_label + 2)))\n",
    "    tracks = []\n",
    "    for t, frame in enumerate(y):\n",
    "        centers = skimage.measure.regionprops(frame)\n",
    "        for c in centers:\n",
    "            tracks.append(\n",
    "                [colorperm[c.label], t, int(c.centroid[0]), int(c.centroid[1])]\n",
    "            )\n",
    "    tracks = np.array(tracks)\n",
    "    tracks = tracks[tracks[:, 0].argsort()]\n",
    "\n",
    "    graph = {}\n",
    "    if links is not None:\n",
    "        divisions = links[links[:, 3] != 0]\n",
    "        for d in divisions:\n",
    "            if (\n",
    "                colorperm[d[0]] not in tracks[:, 0]\n",
    "                or colorperm[d[3]] not in tracks[:, 0]\n",
    "            ):\n",
    "                continue\n",
    "            graph[colorperm[d[0]]] = [colorperm[d[3]]]\n",
    "\n",
    "    viewer.add_labels(y, name=f\"{name}_detections\")\n",
    "    viewer.layers[f\"{name}_detections\"].contour = 3\n",
    "    viewer.add_tracks(tracks, name=f\"{name}_tracks\", graph=graph)\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, y, links.to_numpy(), \"ground_truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9fa60",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f791f97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 1.1\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.1: Highlight the cell divisions</h3>\n",
    "\n",
    "The visualization of the ground truth tracks are useful to grasp this video, but it is still hard see the cell divisions. Given the dense annotations `y` and the track links `links`, write a function to create a new layer that highlights the pairs of daughter cells just after mitosis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3edbe8e",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Expected outcome:<br>\n",
    "<figure style=\"display:inline-block\">\n",
    "    <img src=\"figures/prediv.png\" width=\"400\" />\n",
    "    <figcaption>frame 6</figcaption>\n",
    "</figure>\n",
    "<figure style=\"display:inline-block\">\n",
    "    <img src=\"figures/postdiv.png\" width=\"400\" />\n",
    "    <figcaption>frame 7</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2341d031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_divisions(img_labels, links):\n",
    "    \"\"\"Function to highlight divisions.\n",
    "\n",
    "    Copies over the labels of daughter nuclei just after division into an empty numpy array.\n",
    "\n",
    "    Args:\n",
    "        img_labels: numpy array of shape (time, height, width).\n",
    "            Each nucleus is marked with a unique integer ID.\n",
    "        links: pandas DataFrame of tracklets with columns\n",
    "            `track_id`, `from` (frame number), `to` (frame number), `parent_id`.\n",
    "            If parent_id = 0, the tracklet is not associated to any mother cell.\n",
    "    Returns:\n",
    "        img_divisons: numpy array of shape (time, height, width).\n",
    "            Only the daughter nuclei right after mitosis are marked.\n",
    "    \"\"\"\n",
    "\n",
    "    img_divisions = np.zeros_like(img_labels)\n",
    "    daughters = links[\n",
    "        links.parent_id != 0\n",
    "    ]  # identify daughters i.e. links whose parent_id is not zero\n",
    "\n",
    "    for _, d in daughters.iterrows():\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        print(d)\n",
    "\n",
    "    return img_divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423734d1",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution Exercise 1.1\n",
    "def extract_divisions(img_labels, links):\n",
    "    \"\"\"Function to highlight divisions.\n",
    "\n",
    "    Copies over the labels of daughter nuclei just after division into an empty numpy array.\n",
    "\n",
    "    Args:\n",
    "        img_labels: numpy array of shape (time, height, width).\n",
    "            Each nucleus is marked with a unique integer ID.\n",
    "        links: pandas DataFrame of tracklets with columns\n",
    "            `track_id`, `from` (frame number), `to` (frame number), `parent_id`.\n",
    "            If parent_id = 0, the tracklet is not associated to any mother cell.\n",
    "    Returns:\n",
    "        img_divisons: numpy array of shape (time, height, width).\n",
    "            Only the daughter nuclei right after mitosis are marked.\n",
    "    \"\"\"\n",
    "    img_divisions = np.zeros_like(img_labels)\n",
    "    daughters = links[links.parent_id != 0]\n",
    "\n",
    "    for _, d in daughters.iterrows():\n",
    "        frame_divs = img_divisions[d[\"from\"]]\n",
    "        frame_lbls = img_labels[d[\"from\"]]\n",
    "        daughter_id = d[\"track_id\"]\n",
    "        frame_divs[frame_lbls == daughter_id] = daughter_id\n",
    "\n",
    "    return img_divisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9ae1a1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Test your function with this minimal example (with 1D toy \"images\" of shape (time, height))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b09c74",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "def test_extract_divisions():\n",
    "    y = np.array([[0, 10, 0, 0], [0, 11, 12, 13], [0, 11, 12, 13], [0, 11, 0, 13]])\n",
    "    links = pd.DataFrame(\n",
    "        [[11, 1, 3, 10], [12, 1, 2, 10]],\n",
    "        columns=[\"track_id\", \"from\", \"to\", \"parent_id\"],\n",
    "    )\n",
    "    divs = extract_divisions(y, links)\n",
    "    expected_divs = np.array([[0, 0, 0, 0], [0, 11, 12, 0], [0, 0, 0, 0], [0, 0, 0, 0]])\n",
    "    if np.all(divs == expected_divs):\n",
    "        print(\"Success :)\")\n",
    "    else:\n",
    "        print(f\"Output\\n{divs}\\ndoes not match expected output\\n{expected_divs}\")\n",
    "\n",
    "\n",
    "test_extract_divisions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7c9c24",
   "metadata": {},
   "source": [
    "Visualize the output of your function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6342a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "divisions = extract_divisions(y, links)\n",
    "viewer.add_labels(divisions, name=\"divisions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd26741",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad678fae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Object detection using a pre-trained neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07c175",
   "metadata": {},
   "source": [
    "Now let's assume we have just acquired the raw video and want to track the cells in it from scratch! The first step is detecting the nuclei in each frame.\n",
    "\n",
    "We wil use **StarDist** (Schmidt et al., MICCAI 2018), a robust deep-learning based detection algorithm for cell nuclei. It represents objects as star-convex polygons, which in turn can be represented by a center point and distances along predefined rays going out from the center point.\n",
    "Please refer to the paper for details.\n",
    "\n",
    "We will load a pretrained StarDist model and directly run detection in the video at hand.\n",
    "\n",
    "[Schmidt, Uwe, et al. \"Cell detection with star-convex polygons.\" MICCAI, 2018.](https://link.springer.com/chapter/10.1007/978-3-030-00934-2_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "model = StarDist2D.from_pretrained(\"2D_versatile_fluo\")\n",
    "(detections, details), (prob, _) = model.predict_instances(\n",
    "    x[idx], scale=(1, 1), return_predict=True\n",
    ")\n",
    "plot_img_label(x[idx], detections, lbl_title=\"detections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef45de",
   "metadata": {},
   "source": [
    "Here we visualize in detail the polygons we have detected with StarDist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc45c56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "coord, points, polygon_prob = details[\"coord\"], details[\"points\"], details[\"prob\"]\n",
    "plt.figure(figsize=(24, 12))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Predicted Polygons\")\n",
    "_draw_polygons(coord, points, polygon_prob, show_dist=True)\n",
    "plt.imshow(x[idx], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Object center probability\")\n",
    "plt.imshow(prob, cmap=\"magma\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a8560",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Exercise 1.2\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.2: Explore the parameters of cell detection</h3>\n",
    "\n",
    "Explore the following aspects of the detection algorithm:\n",
    "- The `scale` parameter of the function `predict_instances` downscales (< 1) or upscales (> 1) the images by the given factor before feeding them to the neural network. How do the detections change if you adjust it?\n",
    "- Inspect false positive and false negative detections. Do you observe patterns?\n",
    "- So far we have used a StarDist model off the shelf. Luckily, we also have a StarDist model that was trained on a very similar breast cancer cell dataset (from https://zenodo.org/record/4034976#.Yv-aNPFBzao). Load it with `model = StarDist2D(None, name=\"stardist_breast_cancer\", basedir=\"models\")` and qualitatively observe differences.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398bea6",
   "metadata": {},
   "source": [
    "Detect centers and segment nuclei in all images of the time lapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df73c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = (1.0, 1.0)\n",
    "pred = [\n",
    "    model.predict_instances(xi, show_tile_progress=False, scale=scale) for xi in tqdm(x)\n",
    "]\n",
    "detections = [xi[0] for xi in pred]\n",
    "detections = np.stack(\n",
    "    [skimage.segmentation.relabel_sequential(d)[0] for d in detections]\n",
    ")  # ensure that label ids are contiguous and start at 1 for each frame\n",
    "centers = [xi[1][\"points\"] for xi in pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8d70a4",
   "metadata": {},
   "source": [
    "Visualize the dense detections. Note that they are still not linked and therefore randomly colored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "viewer.add_labels(detections, name=f\"detections_scale_{scale}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab002f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211841bd",
   "metadata": {},
   "source": [
    "We see that the number of detections increases over time, corresponding to the cells that insert the field of view from below during the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dc2235",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(centers)), [len(xi) for xi in centers])\n",
    "plt.title(f\"Number of detections in each frame (scale={scale})\")\n",
    "plt.xticks(range(len(centers)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b49cf3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 1\n",
    "<div class=\"alert alert-block alert-success\"><h3>Checkpoint 1: We have good detections, now on to the linking.</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af950c9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions for greedy linking by nearest neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386151db",
   "metadata": {},
   "source": [
    "The detections in each frame now need to be linked in time to form tracks. In the following exercises, we will explore different ways of doing this.\n",
    "\n",
    "We will start with the simplest algorithm: We take a pair of adjacent frames and compute a distance function between each detection $p \\in P$ in frame $t$ and each detection $q \\in Q$ in frame $t+1$. For example, we can calculate the euclidian distance between the two centroids of detections. This can be written as a matrix of size $|P| \\times |Q|$.\n",
    "\n",
    "We want to minimize the total distance of the links we assign. A *greedy* (locally optimal) algorithm to do so is iteratively linking detections with the minimum distance that remains in the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18ed4a",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## Exercise 1.3\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.3: Write a function that computes pairwise euclidian distances given two lists of points, with two simple for-loops.</h3></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f4deab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "def pairwise_euclidian_distance(points0, points1):\n",
    "    \"\"\"Computes pairwise euclidian distances of two lists of points.\n",
    "\n",
    "    Args:\n",
    "        points0, points1: Lists of point locations (x,y).\n",
    "    Returns:\n",
    "        dists: numpy array of size (#points0, #points1).\n",
    "    \"\"\"\n",
    "    dists = np.zeros((len(points0), len(points1)))\n",
    "\n",
    "    ######################\n",
    "    ### YOUR CODE HERE ###\n",
    "    ######################\n",
    "\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d3c62",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution Exercise 1.3\n",
    "def pairwise_euclidian_distance(points0, points1):\n",
    "    # Iterative pairwise euclidian distance\n",
    "    dists = np.zeros((len(points0), len(points1)))\n",
    "    for i, p0 in enumerate(points0):\n",
    "        for j, p1 in enumerate(points1):\n",
    "            dists[i, j] = np.sqrt(((p0 - p1) ** 2).sum())\n",
    "\n",
    "    return dists\n",
    "\n",
    "\n",
    "# def pairwise_euclidian_distance(points0, points1):\n",
    "#     # Numpy-based, but still slow\n",
    "#     print(\"Vectorized pairwise euclidian distance\")\n",
    "#     return np.apply_along_axis(\n",
    "#         np.linalg.norm,\n",
    "#         2,\n",
    "#         points0[:, None, :] - points1[None, :, :]\n",
    "#     )\n",
    "\n",
    "# def pairwise_euclidian_distance(points0, points1):\n",
    "#     print(\"Scipy pairwise euclidian distance\")\n",
    "#     return scipy.spatial.distance.cdist(points0, points1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97996dc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "Here are two (almost random ;)) lists of points to test your function on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88538bd0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "green_points = np.load(\"points.npz\")[\"green\"]\n",
    "cyan_points = np.load(\"points.npz\")[\"cyan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfccf0ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "%time dists = pairwise_euclidian_distance(green_points, cyan_points)\n",
    "assert np.allclose(dists, np.load(\"points.npz\")[\"dists_green_cyan\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc351718",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# You just calculated the distances between the green and the cyan color patches in the MBL logo ;)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(green_points[:, 0], green_points[:, 1], c=\"yellowgreen\", s=1)\n",
    "plt.scatter(cyan_points[:, 0], cyan_points[:, 1], c=\"darkcyan\", s=1)\n",
    "plt.gca().set_aspect(\"equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce45b30",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## Exercise 1.4\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.4: Complete a function that greedily extracts a nearest neighbor assignment given a cost matrix.</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4e272",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Test your function with the cell below.\n",
    "\n",
    "Hints:\n",
    "- Make sure links do not exceed the cost threshold.\n",
    "- Once you've found the minimum in the matrix with the given code below (`row, col`), set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f6cebf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def nearest_neighbor(cost_matrix, threshold=np.finfo(float).max):\n",
    "    \"\"\"Greedy nearest neighbor assignment.\n",
    "\n",
    "    Each point in both sets can only be assigned once.\n",
    "\n",
    "    Args:\n",
    "        cost_matrix: m x n matrix with pairwise linking costs of two sets of points.\n",
    "        threshold (int): Maximal cost of links.\n",
    "    Returns:\n",
    "        Determined matches as tuple of lists (ids_of_rows, ids_of_columns).\n",
    "    \"\"\"\n",
    "\n",
    "    A = cost_matrix.copy().astype(float)\n",
    "    ids_from = []\n",
    "    ids_to = []\n",
    "\n",
    "    for i in range(min(A.shape[0], A.shape[1])):\n",
    "        # get the indices of the current minimum in the matrix\n",
    "        row, col = np.unravel_index(A.argmin(), A.shape)\n",
    "\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        # Hints:\n",
    "        # 1) Check whether the costs of the link is below `threshold`\n",
    "        # 2) Store the link\n",
    "        # 3) Set the entire row and column of the found link to `threshold`\n",
    "\n",
    "    return np.array(ids_from), np.array(ids_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1fc81b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution exercise 1.4\n",
    "\n",
    "\n",
    "def nearest_neighbor(cost_matrix, threshold=np.finfo(float).max):\n",
    "    \"\"\"Greedy nearest neighbor assignment.\n",
    "\n",
    "    Each point in both sets can only be assigned once.\n",
    "\n",
    "    Args:\n",
    "        cost_matrix: m x n matrix with pairwise linking costs of two sets of points.\n",
    "        threshold (int): Maximal cost of links.\n",
    "    Returns:\n",
    "        matches: List o tuples (from_id, to).\n",
    "    \"\"\"\n",
    "    A = cost_matrix.copy().astype(float)\n",
    "    matches = []\n",
    "\n",
    "    for i in range(min(A.shape[0], A.shape[1])):\n",
    "        row, col = np.unravel_index(A.argmin(), A.shape)\n",
    "\n",
    "        if A.min() > threshold:\n",
    "            break\n",
    "        matches.append((row, col))\n",
    "        A[row, :] = threshold + 1\n",
    "        A[:, col] = threshold + 1\n",
    "\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbcd104",
   "metadata": {},
   "source": [
    "Test your implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4057b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "test_matrix = np.array(\n",
    "    [\n",
    "        [8, 2, 8],\n",
    "        [9, 9, 9],\n",
    "        [1, 8, 8],\n",
    "        [8, 3, 8],\n",
    "    ]\n",
    ")\n",
    "matches = nearest_neighbor(test_matrix, threshold=7)\n",
    "assert np.all(matches[0] == (2, 0)), \"The first match should be (2,0), at cost 1.\"\n",
    "assert np.all(matches[1] == (0, 1)), \"The second match should (0,1), at cost 2.\"\n",
    "assert (\n",
    "    len(matches) == 2\n",
    "), \"You should only produce two matches, since the maximal cost of links is 7.\"\n",
    "print(\"Success :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2d169",
   "metadata": {},
   "source": [
    "## Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ffc8e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Now we provide you with the class `FrameByFrameLinker`, which is a complete class for linking detections in a video with some local frame-by-frame algorithm.\n",
    "\n",
    "This class has many methods that you won't have to worry about, such as iterating over frames, visualizing linked results as well as sanity checks of inputs.\n",
    "\n",
    "However, there are two methods which you will overwrite in the exercises 1.5 - 1.8 by making different [subclasses](https://en.wikipedia.org/wiki/Inheritance_(object-oriented_programming)#Subclasses_and_superclasses) of `FrameByFrameLinker`:\n",
    "- `linking_cost_function` takes the detections of two adjacent frames and calculates a pairwise cost matrix.\n",
    "- `_link_two_frames` takes the cost matrix for two frames and returns lists of links, appearing cells and disappearing cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe26b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrameByFrameLinker:\n",
    "    \"\"\"Base class for linking detections by considering pairs of adjacent frames.\"\"\"\n",
    "\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Calculate features for each detection and extract pairwise costs.\n",
    "\n",
    "        Args:\n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            image0 (optional): image corresponding to detections0\n",
    "            image1 (optional): image corresponding to detections1\n",
    "        Returns:\n",
    "            dists: m x n cost matrix\n",
    "        \"\"\"\n",
    "\n",
    "        # regionprops regions are sorted by label\n",
    "        regions0 = skimage.measure.regionprops(detections0)\n",
    "        points0 = [np.array(r.centroid) for r in regions0]\n",
    "\n",
    "        regions1 = skimage.measure.regionprops(detections1)\n",
    "        points1 = [np.array(r.centroid) for r in regions1]\n",
    "\n",
    "        # Dummy cost function: Absolute difference between index numbers\n",
    "        dists = np.zeros((len(points0), len(points1)))\n",
    "        for i, p0 in enumerate(points0):\n",
    "            for j, p1 in enumerate(points1):\n",
    "                dists[i, j] = np.abs(i - j)\n",
    "\n",
    "        return dists\n",
    "\n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Link two frames.\n",
    "\n",
    "        Args:\n",
    "            cost_matrix: m x n matrix\n",
    "        Returns:\n",
    "            links: Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists:\n",
    "                - idgs_from: [from0, from1 , ...])\n",
    "                - ids_to: [to0, to1 , ...])\n",
    "            births: List of cell ids that newly appear in frame t+1.\n",
    "            deaths: List of cell ids that disappear in frame t+1.\n",
    "\n",
    "            Returned IDs are one-indexed, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        # simply link diagonal elements in the cost matrix\n",
    "        matches = [(i, i) for i in range(min(cost_matrix.shape))]\n",
    "\n",
    "        # split links into two lists for easier handling\n",
    "        ids_from = np.array([from_id for from_id, _ in matches])\n",
    "        ids_to = np.array([to_id for _, to_id in matches])\n",
    "\n",
    "        births = np.array(list(set(range(cost_matrix.shape[1])) - set(ids_to)))\n",
    "        deaths = np.array(list(set(range(cost_matrix.shape[0])) - set(ids_from)))\n",
    "\n",
    "        # Account for +1 offset dense labels, 0 = background\n",
    "        ids_from += 1\n",
    "        ids_to += 1\n",
    "        births += 1\n",
    "        deaths += 1\n",
    "\n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links\n",
    "\n",
    "    def link(self, detections, images=None):\n",
    "        \"\"\"Links detections in t frames.\n",
    "\n",
    "        Args:\n",
    "            detections: List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "            images (optional): List of t numpy arrays of shape (x,y).\n",
    "        Returns:\n",
    "            List of t linking dictionaries, each containing:\n",
    "                \"links\": Tuple of lists (ids frame t, ids frame t+1),\n",
    "                \"births\": List of ids,\n",
    "                \"deaths\": List of ids.\n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        if images is not None:\n",
    "            assert len(images) == len(detections)\n",
    "        else:\n",
    "            images = [None] * len(detections)\n",
    "\n",
    "        links = []\n",
    "        for i in tqdm(range(len(images) - 1), desc=\"Linking\"):\n",
    "            detections0 = detections[i]\n",
    "            detections1 = detections[i + 1]\n",
    "            self._assert_relabeled(detections0)\n",
    "            self._assert_relabeled(detections1)\n",
    "\n",
    "            cost_matrix = self.linking_cost_function(\n",
    "                detections0, detections1, images[i], images[i + 1]\n",
    "            )\n",
    "            li = self._link_two_frames(cost_matrix)\n",
    "            self._assert_links(\n",
    "                links=li, time=i, detections0=detections0, detections1=detections1\n",
    "            )\n",
    "            links.append(li)\n",
    "\n",
    "        return links\n",
    "\n",
    "    def relabel_detections(self, detections, links):\n",
    "        \"\"\"Relabel dense detections according to computed links, births and deaths.\n",
    "\n",
    "        Args:\n",
    "            detections:\n",
    "                List of t numpy arrays of shape (x,y) with contiguous label ids. Background = 0.\n",
    "            links:\n",
    "                List of t linking dictionaries, each containing:\n",
    "                    \"links\": Tuple of lists (ids frame t, ids frame t+1),\n",
    "                    \"births\": List of ids,\n",
    "                    \"deaths\": List of ids.\n",
    "                Ids are one-based, 0 is reserved for background.\n",
    "            Returns:\n",
    "                Numpy array of shape (t,x,y) with relabeled instance ids.\n",
    "        \"\"\"\n",
    "        detections = detections.copy()\n",
    "\n",
    "        assert len(detections) - 1 == len(links)\n",
    "        self._assert_relabeled(detections[0])\n",
    "        out = [detections[0]]\n",
    "        n_tracks = out[0].max()\n",
    "        lookup_tables = [{i: i for i in range(1, out[0].max() + 1)}]\n",
    "\n",
    "        for i in tqdm(range(len(links)), desc=\"Recoloring detections\"):\n",
    "            (ids_from, ids_to) = links[i][\"links\"]\n",
    "            births = links[i][\"births\"]\n",
    "            deaths = links[i + 1][\"deaths\"] if i + 1 < len(links) else []\n",
    "            new_frame = np.zeros_like(detections[i + 1])\n",
    "            self._assert_relabeled(detections[i + 1])\n",
    "\n",
    "            lut = {}\n",
    "            for _from, _to in zip(ids_from, ids_to):\n",
    "                # Copy over ID\n",
    "                new_frame[detections[i + 1] == _to] = lookup_tables[i][_from]\n",
    "                lut[_to] = lookup_tables[i][_from]\n",
    "\n",
    "            # Start new track for birth tracks\n",
    "            for b in births:\n",
    "                if b in deaths:\n",
    "                    continue\n",
    "\n",
    "                n_tracks += 1\n",
    "                lut[b] = n_tracks\n",
    "                new_frame[detections[i + 1] == b] = n_tracks\n",
    "\n",
    "            lookup_tables.append(lut)\n",
    "            out.append(new_frame)\n",
    "\n",
    "        return np.stack(out)\n",
    "\n",
    "    def _assert_links(self, links, time, detections0, detections1):\n",
    "        if len(links[\"links\"][0]) != len(links[\"links\"][1]):\n",
    "            raise RuntimeError(\"Format of links['links'] not correct.\")\n",
    "\n",
    "        if sorted([*links[\"links\"][0], *links[\"deaths\"]]) != list(\n",
    "            range(1, len(np.unique(detections0)))\n",
    "        ):\n",
    "            raise RuntimeError(\n",
    "                f\"Some detections in frame {time} are not properly assigned as either linked or death.\"\n",
    "            )\n",
    "\n",
    "        if sorted([*links[\"links\"][1], *links[\"births\"]]) != list(\n",
    "            range(1, len(np.unique(detections1)))\n",
    "        ):\n",
    "            raise RuntimeError(\n",
    "                f\"Some detections in frame {time + 1} are not properly assigned as either linked or birth.\"\n",
    "            )\n",
    "\n",
    "        for b in links[\"births\"]:\n",
    "            if b in links[\"links\"][1]:\n",
    "                raise RuntimeError(\n",
    "                    f\"Links frame {time+1}: Detection {b} marked as birth, but also linked.\"\n",
    "                )\n",
    "\n",
    "        for d in links[\"deaths\"]:\n",
    "            if d in links[\"links\"][0]:\n",
    "                raise RuntimeError(\n",
    "                    f\"Links frame {time}: Detection {d} marked as death, but also linked.\"\n",
    "                )\n",
    "\n",
    "    def _assert_relabeled(self, x):\n",
    "        if x.min() < 0:\n",
    "            raise ValueError(\"Negative ID in detections.\")\n",
    "        if x.min() == 0:\n",
    "            n = x.max() + 1\n",
    "        else:\n",
    "            n = x.max()\n",
    "        if n != len(np.unique(x)):\n",
    "            raise ValueError(\"Detection IDs are not contiguous.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52539fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_linker = FrameByFrameLinker()\n",
    "dummy_links = dummy_linker.link(detections)\n",
    "dummy_tracks = dummy_linker.relabel_detections(detections, dummy_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb1f3f5",
   "metadata": {},
   "source": [
    "Visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f39b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, dummy_tracks, name=\"dummy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb9079",
   "metadata": {},
   "source": [
    "The extracted tracks are completely off. Let's fix that :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816fd3c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4354f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "lines_to_next_cell": 2
   },
   "source": [
    "## Exercise 1.5\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.5: Complete a thresholded nearest neighbor linker using your functions from exercises 1.3 and 1.4.</h3>\n",
    "\n",
    "You have to complete two methods:\n",
    "\n",
    "- Method 1 (`linking_cost_function`): Given dense detections in a pair of frames, extract their centroids and calculate pairwise euclidian distances between them.\n",
    "- Method 2 (`_link_two_frames`): We greedily find the nearest neighbors in two frames given the cost matrix. If the cost is below a threshold $\\tau$, link the two objects.\n",
    "    - Complete the function such that it returns all unlinked detections in frame $t$ as death events and all unlinked detections in frame $t+1$ as birth events.\n",
    "    - Explore different values of threshold $\\tau$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9e887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighborLinkerEuclidian(FrameByFrameLinker):\n",
    "    def __init__(self, threshold=sys.float_info.max, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            threshold (float): Maximum euclidian distance for linking.\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Get centroids from detections and compute pairwise euclidian distances.\n",
    "\n",
    "        Args:\n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "        Returns:\n",
    "            m x n cost matrix\n",
    "        \"\"\"\n",
    "        # Extract centroids from detections. `regionprops` regions are already sorted by label id.\n",
    "        regions0 = skimage.measure.regionprops(detections0)\n",
    "        points0 = [np.array(r.centroid) for r in regions0]\n",
    "\n",
    "        regions1 = skimage.measure.regionprops(detections1)\n",
    "        points1 = [np.array(r.centroid) for r in regions1]\n",
    "\n",
    "        dists = np.zeros((detections0.max(), detections1.max()))\n",
    "\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        # Apply your pairwise euclidian cost function from Exercise 1.3\n",
    "\n",
    "        return dists\n",
    "\n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Greedy nearest neighbor assignment.\n",
    "\n",
    "        Returns:\n",
    "            links: Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists:\n",
    "                - idgs_from: [from0, from1 , ...])\n",
    "                - ids_to: [to0, to1 , ...])\n",
    "            births: List of cell ids that newly appear in frame t+1.\n",
    "            deaths: List of cell ids that disappear in frame t+1.\n",
    "\n",
    "            Returned IDs are one-indexed, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "\n",
    "        # Applying your nearest neighbor cost function from exercise 1.4\n",
    "        matches = nearest_neighbor(cost_matrix, threshold=self.threshold)\n",
    "\n",
    "        # split links into two lists for easier handling\n",
    "        ids_from = np.array([from_id for from_id, _ in matches])\n",
    "        ids_to = np.array([to_id for _, to_id in matches])\n",
    "\n",
    "        births = np.array(\n",
    "            [\n",
    "                ######################\n",
    "                ### YOUR CODE HERE ###\n",
    "                ######################\n",
    "                # All unmatched detections in frame t+1\n",
    "                # Hint: use python `set` operations\n",
    "            ]\n",
    "        )\n",
    "        deaths = np.array(\n",
    "            [\n",
    "                ######################\n",
    "                ### YOUR CODE HERE ###\n",
    "                ######################\n",
    "                # All unmatched detections in frame t\n",
    "                # Hint: use python `set` operations\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from += 1\n",
    "        ids_to += 1\n",
    "        births += 1\n",
    "        deaths += 1\n",
    "\n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c0d262",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution Exercise 1.5\n",
    "class NearestNeighborLinkerEuclidian(FrameByFrameLinker):\n",
    "    def __init__(self, threshold=sys.float_info.max, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            threshold (float): Maximum euclidian distance for linking.\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Get centroids from detections and compute pairwise euclidian distances.\n",
    "\n",
    "        Args:\n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "        Returns:\n",
    "            m x n cost matrix\n",
    "        \"\"\"\n",
    "        # Extract centroids from detections. `regionprops` regions are already sorted by label id.\n",
    "        regions0 = skimage.measure.regionprops(detections0)\n",
    "        points0 = [np.array(r.centroid) for r in regions0]\n",
    "\n",
    "        regions1 = skimage.measure.regionprops(detections1)\n",
    "        points1 = [np.array(r.centroid) for r in regions1]\n",
    "\n",
    "        # Apply your pairwise euclidian cost function from Exercise 1.3\n",
    "        dists = pairwise_euclidian_distance(points0, points1)\n",
    "\n",
    "        return dists\n",
    "\n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Greedy nearest neighbor assignment.\n",
    "\n",
    "        Returns:\n",
    "            links: Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists:\n",
    "                - idgs_from: [from0, from1 , ...])\n",
    "                - ids_to: [to0, to1 , ...])\n",
    "            births: List of cell ids that newly appear in frame t+1.\n",
    "            deaths: List of cell ids that disappear in frame t+1.\n",
    "\n",
    "            Returned IDs are one-indexed, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "\n",
    "        # Applying your nearest neighbor cost function from exercise 1.4\n",
    "        matches = nearest_neighbor(cost_matrix, threshold=self.threshold)\n",
    "\n",
    "        # split links into two lists for easier handling\n",
    "        ids_from = np.array([from_id for from_id, _ in matches])\n",
    "        ids_to = np.array([to_id for _, to_id in matches])\n",
    "\n",
    "        births = np.array(list(set(range(cost_matrix.shape[1])) - set(ids_to)))\n",
    "        deaths = np.array(list(set(range(cost_matrix.shape[0])) - set(ids_from)))\n",
    "\n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from += 1\n",
    "        ids_to += 1\n",
    "        births += 1\n",
    "        deaths += 1\n",
    "\n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bb9672",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_linker = NearestNeighborLinkerEuclidian(threshold=50)\n",
    "nn_links = nn_linker.link(detections)\n",
    "nn_tracks = nn_linker.relabel_detections(detections, nn_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e482a08b",
   "metadata": {},
   "source": [
    "Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, nn_tracks, name=\"nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac22b8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c483c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Checkpoint 2\n",
    "<div class=\"alert alert-block alert-success\"><h3>Checkpoint 2: We built a basic tracking algorithm from scratch :).</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba08e252",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 2,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exercise 1.6\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.6: Estimate the global drift of the data</h3>\n",
    "\n",
    "We can observe that all cells move upwards with an approximately constant displacement in each timestep. Below you have a slightly modified version of `NearestNeighborLinkerEuclidian` with a modified `linking_cost_function` that models linear drift.\n",
    "\n",
    "Find values of `threshold` and `drift` that lead to an improved solution compared to exercise 1.5.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5beeac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighborLinkerDriftCorrection(NearestNeighborLinkerEuclidian):\n",
    "    def __init__(self, drift, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            drift: tuple for drift correction per frame.\n",
    "        \"\"\"\n",
    "        self.drift = np.array(drift)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Get centroids from detections and compute pairwise euclidian distances with drift correction.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            m x n cost matrix\n",
    "        \"\"\"\n",
    "        # regionprops regions are sorted by label\n",
    "        regions0 = skimage.measure.regionprops(detections0)\n",
    "        points0 = [np.array(r.centroid) for r in regions0]\n",
    "\n",
    "        regions1 = skimage.measure.regionprops(detections1)\n",
    "        points1 = [np.array(r.centroid) for r in regions1]\n",
    "\n",
    "        dists = np.zeros((len(points0), len(points1)))\n",
    "        for i, p0 in enumerate(points0):\n",
    "            for j, p1 in enumerate(points1):\n",
    "                dists[i, j] = np.sqrt(((p0 + self.drift - p1) ** 2).sum())\n",
    "\n",
    "        return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "### YOUR CODE HERE ###\n",
    "######################\n",
    "\n",
    "drift_linker = NearestNeighborLinkerDriftCorrection(threshold=200, drift=(0, 0))\n",
    "drift_links = drift_linker.link(detections)\n",
    "drift_tracks = drift_linker.relabel_detections(detections, drift_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137094e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution Exercise 1.6\n",
    "drift_linker = NearestNeighborLinkerDriftCorrection(\n",
    "    threshold=50, drift=(-20, 0)\n",
    ")  # SOLUTION params\n",
    "drift_links = drift_linker.link(detections)\n",
    "drift_tracks = drift_linker.relabel_detections(detections, drift_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aab55c",
   "metadata": {},
   "source": [
    "Visualize results. You should mostly vertically moving tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7cc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, drift_tracks, name=\"drift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06e8292",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bbec49",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Optimal frame-by-frame matching (*Linear assignment problem* or *Weighted bipartite matching*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180478f3",
   "metadata": {},
   "source": [
    "The nearest neighbor algorithm above will not pick the best solution in many cases. For example, it does not consider the local arrangement of a few detections to create links, something which the human visual system is very good at.\n",
    "\n",
    "We need a better optimization algorithm to minimize the total minimal linking distance between two frames. To use a classic and efficient optimization algorithm, we will represent this linking problem as a bipartite graph. Here is an example:\n",
    "\n",
    "<img src=\"figures/bipartite_graph.png\" width=\"300\"/>\n",
    "\n",
    "Red vertices correspond to detections in frame $t$, blue vertices to detections in frame $t+1$. Since we know that we don't want to link a detection to another one from the same frame, possible edges only connect blue vertices to red vertices, but not within each set.\n",
    "\n",
    "We can also put weights on the edges, which correspond the distanes we have calculated. The task is now to prune the edges of this graph such that each vertex has at most one incident edge. This is called a *weighted bipartite matching* or *linear assignment problem (LAP)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32294251",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "In the seminal tracking algorithm proposed by Jaqaman et al. (2008), the bipartite matching additionally includes cost for not linking a vertex. An unlinked vertex from frame $t$ corresponds to the death of a cell, an unlinked vertex from frame $t+1$ to the birth of a cell. Here is the cost matrix in detail:\n",
    "\n",
    "<img src=\"figures/LAP_cost_matrix.png\" width=\"300\"/>\n",
    "\n",
    "\n",
    "from [Jaqaman, Khuloud, et al. \"Robust single-particle tracking in live-cell time-lapse sequences.\" Nature Methods (2008)](https://www.nature.com/articles/nmeth.1237)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e899c455",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Exercise 1.7\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.7: Perform optimal frame-by-frame linking</h3>\n",
    "\n",
    "Set up the cost matrix following Jaqaman et al. (2008) such that you can use [`scipy.optimize.linear_sum_assignment`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.linear_sum_assignment.html) to solve the matching problem in the bipartite graph.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d641f31",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class BipartiteMatchingLinker(FrameByFrameLinker):\n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold=sys.float_info.max,\n",
    "        drift=(0, 0),\n",
    "        birth_cost_factor=1.05,\n",
    "        death_cost_factor=1.05,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            threshold (float): Maximum euclidian distance for linking.\n",
    "            drift: tuple of (x,y) drift correction per frame.\n",
    "            birth_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "            death_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        self.drift = np.array(drift)\n",
    "        self.birth_cost_factor = birth_cost_factor\n",
    "        self.death_cost_factor = death_cost_factor\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Get centroids from detections and compute pairwise euclidian distances with drift correction.\n",
    "\n",
    "        Args:\n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "        Returns:\n",
    "            m x n cost matrix\n",
    "        \"\"\"\n",
    "        # regionprops regions are sorted by label\n",
    "        regions0 = skimage.measure.regionprops(detections0)\n",
    "        points0 = [np.array(r.centroid) for r in regions0]\n",
    "\n",
    "        regions1 = skimage.measure.regionprops(detections1)\n",
    "        points1 = [np.array(r.centroid) for r in regions1]\n",
    "\n",
    "        dists = []\n",
    "        for p0 in points0:\n",
    "            for p1 in points1:\n",
    "                dists.append(np.sqrt(((p0 + self.drift - p1) ** 2).sum()))\n",
    "\n",
    "        dists = np.array(dists).reshape(len(points0), len(points1))\n",
    "\n",
    "        return dists\n",
    "\n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Weighted bipartite matching with square matrix from Jaqaman et al (2008).\n",
    "\n",
    "        Args:\n",
    "            cost_matrix: m x n matrix.\n",
    "        Returns:\n",
    "            Linking dictionary:\n",
    "                \"links\": Tuple of lists (ids frame t, ids frame t+1),\n",
    "                \"births\": List of ids,\n",
    "                \"deaths\": List of ids.\n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "        cost_matrix = cost_matrix.copy().astype(float)\n",
    "\n",
    "        # Cost of birth event\n",
    "        b = self.birth_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "\n",
    "        # Cost of death event\n",
    "        d = self.death_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "\n",
    "        # High value to represent impossible link\n",
    "        no_link = max(cost_matrix.max(), max(b, d)) * 1e9\n",
    "\n",
    "        ### Set up the blockwise square cost matrix for the linear assignment problem ###\n",
    "\n",
    "        # Set all linking costs exceeding `threshold` to `no_link`.\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "\n",
    "        # Set up the lower right block correctly, instead of all 0s.\n",
    "        # It should be the transpose of the upper left block.\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        lower_right = np.zeros((cost_matrix.shape[1], cost_matrix.shape[0]))\n",
    "\n",
    "        # Set up the block for death costs correctly, instead of all 0s.\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        deaths = np.full(\n",
    "            shape=(cost_matrix.shape[0], cost_matrix.shape[0]), fill_value=0\n",
    "        )\n",
    "\n",
    "        # Set up the block for birth costs correctly, instead of all 0s.\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        births = np.full(\n",
    "            shape=(cost_matrix.shape[1], cost_matrix.shape[1]), fill_value=0\n",
    "        )\n",
    "\n",
    "        # Assemble blockwise cost matrix\n",
    "        square_cost_matrix = np.block(\n",
    "            [\n",
    "                [cost_matrix, deaths],\n",
    "                [births, lower_right],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        ### Run linear assignment problem ###\n",
    "\n",
    "        row_ind, col_ind = scipy.optimize.linear_sum_assignment(square_cost_matrix)\n",
    "\n",
    "        # Write out matches, birth and death events to the class's format\n",
    "        ids_from = []\n",
    "        ids_to = []\n",
    "        births = []\n",
    "        deaths = []\n",
    "        for row, col in zip(row_ind, col_ind):\n",
    "            if row < cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                ids_from.append(row)\n",
    "                ids_to.append(col)\n",
    "\n",
    "            if row >= cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                births.append(col)\n",
    "            if row < cost_matrix.shape[0] and col >= cost_matrix.shape[1]:\n",
    "                deaths.append(row)\n",
    "\n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from = np.array(ids_from) + 1\n",
    "        ids_to = np.array(ids_to) + 1\n",
    "        births = np.array(births) + 1\n",
    "        deaths = np.array(deaths) + 1\n",
    "\n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3075e02",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Solution exercise 1.7\n",
    "\n",
    "\n",
    "class BipartiteMatchingLinker(FrameByFrameLinker):\n",
    "    \"\"\".\n",
    "\n",
    "    Args:\n",
    "        threshold (float): Maximum euclidian distance for linking.\n",
    "        drift: tuple of (x,y) drift correction per frame.\n",
    "        birth_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "        death_cost_factor (float): Multiply factor with maximum entry in cost matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold=np.finfo(float).max,\n",
    "        drift=(0, 0),\n",
    "        birth_cost_factor=1.05,\n",
    "        death_cost_factor=1.05,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.threshold = threshold\n",
    "        self.drift = np.array(drift)\n",
    "        self.birth_cost_factor = birth_cost_factor\n",
    "        self.death_cost_factor = death_cost_factor\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Get centroids from detections and compute pairwise euclidian distances with drift correction.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            m x n cost matrix\n",
    "        \"\"\"\n",
    "        # regionprops regions are sorted by label\n",
    "        regions0 = skimage.measure.regionprops(detections0)\n",
    "        points0 = [np.array(r.centroid) for r in regions0]\n",
    "\n",
    "        regions1 = skimage.measure.regionprops(detections1)\n",
    "        points1 = [np.array(r.centroid) for r in regions1]\n",
    "\n",
    "        dists = []\n",
    "        for p0 in points0:\n",
    "            for p1 in points1:\n",
    "                dists.append(np.sqrt(((p0 + self.drift - p1) ** 2).sum()))\n",
    "\n",
    "        dists = np.array(dists).reshape(len(points0), len(points1))\n",
    "\n",
    "        return dists\n",
    "\n",
    "    def _link_two_frames(self, cost_matrix):\n",
    "        \"\"\"Weighted bipartite matching with square matrix from Jaqaman et al (2008).\n",
    "\n",
    "        Args:\n",
    "\n",
    "            cost_matrix: m x n matrix.\n",
    "\n",
    "        Returns:\n",
    "            \"links\":\n",
    "\n",
    "                Tuple of lists. Links from frame t to frame t+1 of form (from0, to0) are split up into two lists:\n",
    "                    - idgs_from: [from0, from1 , ...])\n",
    "                    - ids_to: [to0, to1 , ...])\n",
    "\n",
    "                \"births\": List of ids from frame t that are\n",
    "                \"deaths\": List of ids.\n",
    "\n",
    "            Ids are one-based, 0 is reserved for background.\n",
    "        \"\"\"\n",
    "\n",
    "        cost_matrix = cost_matrix.copy().astype(float)\n",
    "\n",
    "        # Cost of birth event\n",
    "        b = self.birth_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "\n",
    "        # Cost of death event\n",
    "        d = self.death_cost_factor * min(self.threshold, cost_matrix.max())\n",
    "\n",
    "        # High value to represent impossible link\n",
    "        no_link = max(cost_matrix.max(), max(b, d)) * 1e9\n",
    "\n",
    "        ### Set up the blockwise square cost matrix for the linear assignment problem ###\n",
    "\n",
    "        # Set all linking costs exceeding `threshold` to `no_link`\n",
    "        cost_matrix[cost_matrix > self.threshold] = no_link\n",
    "\n",
    "        # Set up the lower right block correctly, instead of all 0s.\n",
    "        lower_right = cost_matrix.transpose()\n",
    "\n",
    "        # Set up the block for death costs correctly, instead of all 0s.\n",
    "        deaths = np.full(\n",
    "            shape=(cost_matrix.shape[0], cost_matrix.shape[0]), fill_value=no_link\n",
    "        )\n",
    "        np.fill_diagonal(deaths, d)\n",
    "\n",
    "        # Set up the block for birth costs correctly, instead of all 0s.\n",
    "        births = np.full(\n",
    "            shape=(cost_matrix.shape[1], cost_matrix.shape[1]), fill_value=no_link\n",
    "        )\n",
    "        np.fill_diagonal(births, b)\n",
    "\n",
    "        # Assemble blockwise cost matrix\n",
    "        square_cost_matrix = np.block(\n",
    "            [\n",
    "                [cost_matrix, deaths],\n",
    "                [births, lower_right],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        ### Run linear assignment problem ###\n",
    "\n",
    "        row_ind, col_ind = scipy.optimize.linear_sum_assignment(square_cost_matrix)\n",
    "\n",
    "        # Write out matches, birth and death events to the class's format\n",
    "        ids_from = []\n",
    "        ids_to = []\n",
    "        births = []\n",
    "        deaths = []\n",
    "        for row, col in zip(row_ind, col_ind):\n",
    "            if row < cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                ids_from.append(row)\n",
    "                ids_to.append(col)\n",
    "\n",
    "            if row >= cost_matrix.shape[0] and col < cost_matrix.shape[1]:\n",
    "                births.append(col)\n",
    "            if row < cost_matrix.shape[0] and col >= cost_matrix.shape[1]:\n",
    "                deaths.append(row)\n",
    "\n",
    "        # Account for +1 offset of the dense labels\n",
    "        ids_from = np.array(ids_from) + 1\n",
    "        ids_to = np.array(ids_to) + 1\n",
    "        births = np.array(births) + 1\n",
    "        deaths = np.array(deaths) + 1\n",
    "\n",
    "        links = {\"links\": (ids_from, ids_to), \"births\": births, \"deaths\": deaths}\n",
    "        return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250f7fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm_linker = BipartiteMatchingLinker(\n",
    "    threshold=50, drift=(-20, 0), birth_cost_factor=1.05, death_cost_factor=1.05\n",
    ")\n",
    "bm_links = bm_linker.link(detections)\n",
    "bm_tracks = bm_linker.relabel_detections(detections, bm_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e048a",
   "metadata": {},
   "source": [
    "Visualize results. You should observe mostly vertically moving tracks, without ever explicitely modelling the drift. This is quite cool :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72ddf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(x)\n",
    "visualize_tracks(viewer, bm_tracks, name=\"bm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c8cad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "viewer = napari.viewer.current_viewer()\n",
    "if viewer:\n",
    "    viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32d734",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "lines_to_next_cell": 2
   },
   "source": [
    "## Exercise 1.8 (Bonus)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"><h3>Exercise 1.8: Explore different features for assigment problem</h3>\n",
    "\n",
    "Explore solving the assignment problem based different features and cost functions.\n",
    "For example:\n",
    "- Different morphological properties of detections (e.g. using `skimage.measure.regionprops`).\n",
    "- Extract texture features from the images, e.g. mean intensity for each detection.\n",
    "- Pairwise *Intersection over Union (IoU)* of detections.\n",
    "- ...\n",
    "\n",
    "Feel free to share features that improved the results with the class :).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601cbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourLinker(BipartiteMatchingLinker):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def linking_cost_function(self, detections0, detections1, image0=None, image1=None):\n",
    "        \"\"\"Your very smart cost function for frame-by-frame linking.\n",
    "\n",
    "        Args:\n",
    "\n",
    "            detections0: image with background 0 and detections 1, ..., m\n",
    "            detections1: image with backgruond 0 and detections 1, ..., n\n",
    "            image0 (optional): image corresponding to detections0\n",
    "            image1 (optional): image corresponding to detections1\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            m x n cost matrix\n",
    "        \"\"\"\n",
    "        return np.zeros((detections0.max(), detections1.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac10adda",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_linker = YourLinker()\n",
    "your_links = your_linker.link(detections)\n",
    "your_tracks = your_linker.relabel_detections(detections, your_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7c67f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
